<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | Just Another Linux Blog]]></title>
  <link href="http://www.chriscowley.me.uk/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://www.chriscowley.me.uk/"/>
  <updated>2014-06-17T11:29:08+02:00</updated>
  <id>http://www.chriscowley.me.uk/</id>
  <author>
    <name><![CDATA[Chris Cowley]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[New Linux Active Directory Integration]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/06/17/new-linux-active-directory-integration/"/>
    <updated>2014-06-17T10:28:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/06/17/new-linux-active-directory-integration</id>
    <content type="html"><![CDATA[<p>This used to be quite complex, but now is astoundingly simple. Now there is a new project call <a href="http://freedesktop.org/software/realmd/">realmd</a>. It is in recent version of Debian (Jessie and Sid) and Ubuntu (since 13.04). For Red Hat types, it is RHEL7 and Fedora (since 18).</p>

<p>If you're on Debian/Ubuntu, install with:</p>

<p><code>
apt-get install realmd
</code></p>

<p>For RHEL/Fedora:</p>

<p><code>
sudo yum install realmd
</code></p>

<p>Now you can go ahead and join the domain:</p>

<p><code>
sudo realm join --user=&lt;admin-user&gt; example.com
</code></p>

<p>That is it, you can check this by running <code>sudo realm list</code>, which will give you something like:</p>

<p><code>
example.com
  type: kerberos
  realm-name: EXAMPLE.COM
  domain-name: example.com
  configured: kerberos-member
  server-software: active-directory
  client-software: sssd
  required-package: oddjob
  required-package: oddjob-mkhomedir
  required-package: sssd
  required-package: adcli
  required-package: samba-common
  login-formats: %U@example.com
  login-policy: allow-realm-logins
</code></p>

<p>By default <code>realmd</code> used SSSD to perform the authentication. This in turn configured Kerberos and LDAP.</p>

<p>My initial testing has been performed with an Active Directory that has "Identity Managment for UNIX" installed. However, I forgot to actually enable my user for UNIX. Even so, it worked perfectly. It sees my Windows groups and defines a home directory of <code>/home/example.com/&lt;username&gt;</code>.</p>

<p>The last step is <code>sudo</code>. If you want to have everyone in <em>Domain Admins</em> have permission to run everything as root, then add the following to <code>sudoers</code>:</p>

<p><code>
%domain\ users@example.com ALL=(ALL)       ALL
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VMware CLI on Ubuntu Saucy Salamander]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/04/09/vmware-cli-on-ubuntu-saucy-salamander/"/>
    <updated>2014-04-09T10:51:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/04/09/vmware-cli-on-ubuntu-saucy-salamander</id>
    <content type="html"><![CDATA[<p>{% img right http://www.datanalyzers.com/VMware-Data-Recovery.jpg %}The current project (as of this week) has me moving away from Openstack for a while. For the next couple of months I will be immersing myself in monitor, metrics and logging. Naturally, this being a shiney new environment, this involves a significant amount of VMware time.</p>

<!-- more -->


<p>I have inherited an Icinga install running on Ubuntu Server, so I will be needing to run CLI commands to create checks. Simply runnning the installer does not work, as the vmware-cli package is a mixture of 32 and 64 bit commands.</p>

<p>First you need to download the CLI from VMware. How to do that is an exercise for the reader, as I cannot be bothered to find the link (hint: it is not hard). Then you need to install a bunch of packages:</p>

<p><code>
sudo apt-get install cpanminus libdata-dump-perl libsoap-lite-perl libclass-methodmaker-perl  libxml-libxml-simple-perl libssl-dev libarchive-zip-perl libuuid-perl lib32z1 lib32ncurses5 lib32bz2-1.0
</code></p>

<p>This includes a bunch of Perl modules for munching through XML, plus some 32-bit libraries so that all the tools can work.</p>

<p>Finally, you can extract the tarball and install the CLI:</p>

<p><code>
tar xvf VMware-vSphere-CLI-5.5.0-1549297.x86_64.tar.gz
cd vmware-vsphere-cli-distrib/
sudo ./vmware-install.pl
</code></p>

<p>I have not tested it, but this will probably be the same process for Debian (at least Wheezy and Sid).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openstack Neutron Performance problems]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/03/31/openstack-neutron-performance-problems/"/>
    <updated>2014-03-31T20:08:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/03/31/openstack-neutron-performance-problems</id>
    <content type="html"><![CDATA[<p>{% img right http://i.imgur.com/fSMzOUE.jpg %}For the last few weeks I have been consulting on a private cloud project for a local company. Unsurprisingly this has been based around the typical Openstack setup.</p>

<ul>
<li>Nova - KVM</li>
<li>Neutron - Openvswitch</li>
<li>Cinder - LVM</li>
<li>Glance - local files</li>
</ul>


<!-- more -->


<p>My architecture is nothing out of the ordinary. A pair of hosts each with 2 networks that look something like this:</p>

<p>{% img https://docs.google.com/drawings/d/11le0qu389WptC78_08Bh92qUCLiCBXiZOhDiESSCnxo/pub?w=960&amp;h=720 %}</p>

<p>All this is configured using Red Hat RDO. I had done all this under both Grizzly and, using RDO, it was 30 minutes to set up.</p>

<p>Given how common and simple the setup, imagine my surprise when it did not work. What do I mean did not work? From the outset I was worried about Neutron. While I am fairly up to date with SDN in theory, I am fairly green in practise. Fortunately, while RDO does not automate it's configuration, there is at least an <a href="http://openstack.redhat.com/Neutron_with_existing_external_network">accurate document</a> in how to configure it.</p>

<p>Now, if I was just using small images that would probably be fine, however this project required Windows images. As a result some problems quickly surfaced. Each time I deployed a new Windows image, everything would lock up:</p>

<ul>
<li>no network access to VM's</li>
<li>Openvswitch going mad (800-1000% CPU)</li>
<li>SSH access via eth0 completely dead</li>
</ul>


<p>It has to be said that I initially barked up the wrong tree, pointing the finger at disk access (usually the problem with shared systems). However it turned out I was wrong.</p>

<p>A brief Serverfault/Twitter with @martenhauville brought up a few suggestions, one of which caught my eye:</p>

<p>{% blockquote @martenhauville https://ask.openstack.org/en/question/25947/openstack-neutron-stability-problems-with-openvswitch/ %}
there are known Neutron configuration challenges to overcome with GRE and MTU settings
{% endblockquote %}</p>

<p>This is where my problem lay: the external switch had an MTU of 1500, Openvswitch also. Finally, <code>ip link</code> in a VM would give you</p>

<pre><code>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br-ex state UP mode DEFAULT qlen 1000
</code></pre>

<p>Everything matches, however I was using GRE tunnels, which add a header to each frame. This was pushing them over 1500 on entry to <code>br-tun</code> causing massive network fragmentation, which basically destroyed Openvswitch every time I performed a large transfer. It showed up when deploying an image, because that is hitting the Glance API over http.</p>

<p>Once armed with this knowledge, the fix is trivial. Add the following to <code>/etc/neutron/dhcp_agent.ini</code>:</p>

<pre><code>dnsmasq_config_file=/etc/neutron/dnsmasq-neutron.conf
</code></pre>

<p>Now create the file <code>/etc/neutron/dnsmasq-neutron.conf</code> which contains the following:</p>

<pre><code>dhcp-option-force=26,1454
</code></pre>

<p>Now you can restart the DHCP agent and all will be well:</p>

<pre><code>service neutron-dhcp-agent restart
</code></pre>

<p>I've gone on a bit in this post, as I feel the background is important. By far the hardest part was diagnosing the problem, without knowing what my background was it would be much harder to narrow down your problem to being the same as mine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NFS with Puppet and an ENC]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc/"/>
    <updated>2014-01-24T20:06:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc</id>
    <content type="html"><![CDATA[<p>{% img right http://puppetlabs.com/sites/default/files/PL_logo_horizontal_RGB_0.svg 200 200 %}Ages ago (it seems) I posted a <a href="http://www.chriscowley.me.uk/blog/2013/04/11/using-hiera-with-puppet/">howto</a> on configure NFS using Puppet and Hiera. I have been using this happily for several months and adding a new share was is as simple as adding a line to a YAML file. I was never completely happy with it though, especially after I decided to deploy <a href="http://www.theforeman.org">The Foreman</a> in my lab.</p>

<!-- more -->


<p>The reason I was never satisfied is because The Foreman makes a really good ENC. I wanted to use this, so I have modified my module to use an ENC rather than Hiera directly.</p>

<p>OK, first I we need to get the module into a position where it uses parameterized classes. This is actually quite simple.</p>

<p>My original manifest is <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/b5d5fe6eba75379fad37255ceddb55208cbe7208/manifests/server.pp">here</a>. The key item is the <em>$exports</em> variable, which is hiera data. All I did was create a class parameter called <em>exports</em> and removed the variable within the class. You can see the new code <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/server.pp">here</a>. I have also moved the <code>list_exports</code> function out into a <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/list_exports.pp">seperate file</a>. Apparently this makes it more readable, although I am not convinced in this instance.</p>

<p>I also took the chance to update my module a bit so that it was not hard-coded to my own lab network. To that end, it will automatically pull out the IP address and netmask of eth0. You can edit this easily enough using your ENC.</p>

<p>{% codeblock lang:puppet manifests/server.pp  %}
  class nfs::server (</p>

<pre><code>$exports = [ '/srv/share'],
$networkallowed = $::network_eth0,
$netmaskallowed = $::netmask_eth0,
</code></pre>

<p>  ) {</p>

<pre><code>// Code here
</code></pre>

<p>  }
{% endcodeblock %}</p>

<p>Next we need a simple ENC to supply the data. An ENC is actually just any script that returns YAML. It has a single parameter, which is the FQDN of the node. I use this:</p>

<p>{% codeblock /usr/local/bin/simple-enc.sh %}</p>

<h1>!/bin/bash</h1>

<p>DATADIR="/var/local/enc"
NODE=$1</p>

<p>cat "${DATADIR}/${NODE}.yaml"
{% endcodeblock %}</p>

<p>Next you need a YAML file that looks like:</p>

<h2>{% codeblock /var/local/enc/nfs.example.lan.yaml %}</h2>

<p>environment: production
classes:
  nfs::server:</p>

<pre><code>exports:
  - /srv/share1
  - /srv/share3
networkallowed: 192.168.0.0
netmaskallowed: 255.255.255.0
</code></pre>

<p>parameters:
{% endcodeblock %}</p>

<p>Finally, you need to enable this on your Puppet master. Add this to <code>/etc/puppet/puppet.conf</code>:</p>

<p>{% codeblock  %}
[master]</p>

<pre><code>node_terminus = exec
external_nodes = /usr/local/bin/simple-enc.sh
</code></pre>

<p>{% endcodeblock %}</p>

<p>Now whenever a node with the FQDN nfs.example.lan syncs with the master it runs <code>/usr/local/bin/simple-enc.sh nfs.examle.lan.yaml</code>. This returns the contents of the YAML file above. The layout of it is pretty logical, but I suggest reading Puppetlabs <a href="http://docs.puppetlabs.com/guides/external_nodes.html">docs</a>.</p>

<p>How is this better than the previous Hiera setup? First I can now use my module with The Foreman which answers my immediate need. Second I can now submit this module to the Forge with a warm fuzzy feeling inside as I am a good citizen. not only does it work with Puppet 3, but also really old versions of Puppet that do not support an ENC or Hiera. It can do this because the user can still edit the class parameters directly, or set the in <code>site.pp</code> (<strong>DON'T DO THAT</strong>).</p>

<p>You can install the module on your own Puppet master with:</p>

<p>```
git clone http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs.git \</p>

<pre><code>/etc/puppet/modules/nfs/
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RHEL and CentOS joining forces]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces/"/>
    <updated>2014-01-08T14:34:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces</id>
    <content type="html"><![CDATA[<p>{% img right http://i.imgur.com/3colCNj.png 200 200 %}Yesterday saw probably the biggest FLOSS news in recent times. Certainly the biggest news of 2014 so far :-) By some freak of overloaded RSS readers, I missed the announcement, but I did see this:</p>

<blockquote class="twitter-tweet" lang="en"><p>Day 1 at the new job. Important stuff first.. Where do I get my Red Hat ?</p>&mdash; Karanbir Singh (@CentOS) <a href="https://twitter.com/CentOS/statuses/420876286785892353">January 8, 2014</a></blockquote>


<script async src="http://www.chriscowley.me.uk//platform.twitter.com/widgets.js" charset="utf-8"></script>


<!-- more -->


<p>It did not take long to dig up <a href="http://community.redhat.com/centos-faq/?utm_content=buffer6403d&amp;utm_source=buffer&amp;utm_medium=twitter&amp;utm_campaign=Buffer">this</a> and <a href="http://lists.centos.org/pipermail/centos-announce/2014-January/020100.html">this</a>, where Red Hat and CentOS respectively announce that they have joined forces. Some things from the announcement struck me:</p>

<blockquote><p> Some of us now work for Red Hat, but not RHEL</p></blockquote>

<p>That is important! This says to me that Red Hat see the value of CentOS as an entity in itself. By not linking the CentOS developers to RHEL in anyway, they are not going to be side-tracking them. Instead, they are simple freeing them up to work more effectively on CentOS.</p>

<blockquote><p>we are now able to work with the Red Hat legal teams</p></blockquote>

<p>QA was always a problem for CentOS, simply because it took place effectively in secret. Now they can just walk down the corridor to talk to the lawyers who would have previously (potentially) sued them, all the potential problems go away.</p>

<h1>The RHEL Ecosystem</h1>

<p>{% pullquote %}
In the beginning there is <a href="http://fedoraproject.org">Fedora</a>), where the RHEL developers get to play. Here is where they can try new things and make mistakes. {"In Fedora things can break without people really worrying"} (especially in Rawhide). The exception to this is my wife as we run it on the family PC and she gets quite frustrated with its foibles. However, she knew she was marrying a geek from the outset, so I will not accept any blame for this.
{% endpullquote %}}</p>

<p>Periodically, the the Fedora developers will pull everything together and create a release that has the potential to be transformed into RHEL. Here they pull together all the things that have be learnt over the last few releases. I consider this an Alpha release of RHEL. At this point, behind the scenes, the RHEL developers will take those packages and start work on the next release of RHEL.</p>

<p>{% pullquote %}
On release of RHEL, Red Hat make the source code available, as required by the terms of the GPL (and other relevant licenses).The thing is, {"Red Hat as a company are built on Open Source"} principles, they firmly believe in them and, best of all, they practise what the preach. They would still be within the letter of the law if the just dumped a bunch of apparently random scripts on a web server. Instead, they publish the SRPM packages used to build RHEL.
{% endpullquote %}</p>

<p>CentOS then take these sources and get to work. By definition they are always beind RHEL. As many know this got pretty bad at one point:</p>

<p>{% img http://www.standalone-sysadmin.com/~matt/centos-delays.jpg center %}</p>

<p>(Thanks to Matt Simmons, aka <a href="http://www.standalone-sysadmin.com">Standalone Sysadmin</a>, from whom I blatantly stole that graph, I'll ask permission later)</p>

<p>Since then, things have got better, with new point releases coming hot on the heels of RHEL. Certainly preparations for EL7 seemed to be going on nicely even before this announcement.</p>

<h1>how does this now affect the two projects</h1>

<p>Both CentOS and Red Hat have a lot to gain from this alliance. {% img right http://i.imgur.com/qbKvXko.jpg 350 350 %}I am sure that there are few people in the wider community who will be upset, but I think that it is a good thing. The reality is that CentOS and RHEL have never been enemies. The people that are using CentOS are just simply never going to pay Red Hat for support they do not need.</p>

<p>When I started at Snell (then Snell &amp; Wilcox), the official line was to use RHEL for all our Linux servers. They had everything paid up for a couple of years at the time. By the time renewal came around the global financial crisis had hit, we had used the support two or three times and each time I had solved the problem before Red Hat answered the ticket. So, we decided to switch to CentOS (which was trivial).</p>

<p>At the other end of the scale you have the web-scale people. For them, paying Red Hat for support is both unnecessary (they have the right people on staff) and prohibitively expensive. When you have tens of thousands of nodes you cannot use a licensing model that support each one.</p>

<p>In the cloud model you also have a problem, in that you are effectively renting an OS. Microsoft and Red Hat you have an administrative overhead of ensuring you have the right licenses available. In my experience Red Hat make it a lot easier, but it is an overhead none the less.</p>

<p>All three of these will get a huge benefit. Now that the CentOS developers are on staff at Red Hat they have direct access to the source code. There should no longer be any need to wait for RHEL to drop before they start building. Red Hat will be supplying infrastructure and community support, which will also be a massive bonus.</p>

<p>So what do Red Hat gain? In terms of new customers, they may get some of that first group. These are the people that may well do their testing with CentOS, but may now choose to go production with RHEL. I certainly would be more willing to now that XFS is not in a separate (expensive) RAN channel. I do not see the cloud or web-scale people changing to a paid support model. It will remain prohibitively expensive for them.</p>

<p>I think they biggest thing that Red Hat will gain is that get to give Oracle a good kicking. Oracle basically do the same thing as CentOS, but they stick a thumping great big support charge on it. To be honest I have never really worked out why anyone would use it. Yes they are cheaper than Red Hat, but not by much. A couple of years ago Red Hat took steps to <a href="http://www.theregister.co.uk/2011/03/04/red_hat_twarts_oracle_and_novell_with_change_to_source_code_packaging/">make life harder</a>. That had an unfortunate knock-on effect on CentOS, causing the huge delay in CentOS 6. Now CentOS should not have that problem as they are closer to source.</p>

<h1>TL;DR</h1>

<p>CentOS and RHEL joining forces is in my opinion a really good thing, with both parties getting significant benefits. Granted they are bit less tangible for Red Hat, but that does not make them any less significant.</p>

<p>Personally I am really excited to see what it is in store - especially from CentOS. I even have a couple of SIG ideas too.</p>
]]></content>
  </entry>
  
</feed>
