<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | Just Another Linux Blog]]></title>
  <link href="http://www.chriscowley.me.uk/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://www.chriscowley.me.uk/"/>
  <updated>2014-03-23T19:23:15+01:00</updated>
  <id>http://www.chriscowley.me.uk/</id>
  <author>
    <name><![CDATA[Chris Cowley]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[NFS with Puppet and an ENC]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc/"/>
    <updated>2014-01-24T20:06:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://puppetlabs.com/sites/default/files/PL_logo_horizontal_RGB_0.svg" width="200" height="200">Ages ago (it seems) I posted a <a href="http://www.chriscowley.me.uk/blog/2013/04/11/using-hiera-with-puppet/">howto</a> on configure NFS using Puppet and Hiera. I have been using this happily for several months and adding a new share was is as simple as adding a line to a YAML file. I was never completely happy with it though, especially after I decided to deploy <a href="http://www.theforeman.org">The Foreman</a> in my lab.</p>

<!-- more -->


<p>The reason I was never satisfied is because The Foreman makes a really good ENC. I wanted to use this, so I have modified my module to use an ENC rather than Hiera directly.</p>

<p>OK, first I we need to get the module into a position where it uses parameterized classes. This is actually quite simple.</p>

<p>My original manifest is <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/b5d5fe6eba75379fad37255ceddb55208cbe7208/manifests/server.pp">here</a>. The key item is the <em>$exports</em> variable, which is hiera data. All I did was create a class parameter called <em>exports</em> and removed the variable within the class. You can see the new code <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/server.pp">here</a>. I have also moved the <code>list_exports</code> function out into a <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/list_exports.pp">seperate file</a>. Apparently this makes it more readable, although I am not convinced in this instance.</p>

<p>I also took the chance to update my module a bit so that it was not hard-coded to my own lab network. To that end, it will automatically pull out the IP address and netmask of eth0. You can edit this easily enough using your ENC.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>manifests/server.pp  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='puppet'><span class='line'>  <span class="kd">class</span> <span class="nc">nfs::server</span> <span class="p">(</span><span class="err">&lt;/</span><span class="ss">p</span><span class="err">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="err">&lt;</span><span class="ss">pre</span><span class="err">&gt;&lt;</span><span class="ss">code</span><span class="err">&gt;</span><span class="nv">$exports</span> <span class="p">=</span> <span class="p">[</span> <span class="s1">&#39;/srv/share&#39;</span><span class="p">],</span>
</span><span class='line'><span class="nv">$networkallowed</span> <span class="p">=</span> <span class="nv">$::network_eth0</span><span class="p">,</span>
</span><span class='line'><span class="nv">$netmaskallowed</span> <span class="p">=</span> <span class="nv">$::netmask_eth0</span><span class="p">,</span>
</span><span class='line'><span class="err">&lt;</span><span class="sr">/code&gt;&lt;/</span><span class="ss">pre</span><span class="err">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="err">&lt;</span><span class="ss">p</span><span class="err">&gt;</span>  <span class="p">)</span> <span class="p">{</span><span class="err">&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="err">&lt;pre&gt;&lt;code&gt;//</span> <span class="err">Code</span> <span class="err">here</span>
</span><span class='line'><span class="err">&lt;/code&gt;&lt;/pre&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="err">&lt;p&gt;</span>  }
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Next we need a simple ENC to supply the data. An ENC is actually just any script that returns YAML. It has a single parameter, which is the FQDN of the node. I use this:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>/usr/local/bin/simple-enc.sh </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h1&gt;!/bin/bash&lt;/h1&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;DATADIR<span class="o">=</span><span class="s2">&quot;/var/local/enc&quot;</span>
</span><span class='line'><span class="nv">NODE</span><span class="o">=</span><span class="nv">$1</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;cat <span class="s2">&quot;${DATADIR}/${NODE}.yaml&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Next you need a YAML file that looks like:</p>

<h2><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>/var/local/enc/nfs.example.lan.yaml </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">&lt;/h2&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">&lt;p&gt;environment</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">production</span>
</span><span class='line'><span class="l-Scalar-Plain">classes</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">nfs::server:&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">&lt;pre&gt;&lt;code&gt;exports</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/srv/share1</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/srv/share3</span>
</span><span class='line'><span class="l-Scalar-Plain">networkallowed</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">192.168.0.0</span>
</span><span class='line'><span class="l-Scalar-Plain">netmaskallowed</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">255.255.255.0</span>
</span><span class='line'><span class="l-Scalar-Plain">&lt;/code&gt;&lt;/pre&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">&lt;p&gt;parameters</span><span class="p-Indicator">:</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Finally, you need to enable this on your Puppet master. Add this to <code>/etc/puppet/puppet.conf</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[master]&lt;/p>
</span><span class='line'>
</span><span class='line'>&lt;pre>&lt;code>node_terminus = exec
</span><span class='line'>external_nodes = /usr/local/bin/simple-enc.sh
</span><span class='line'>&lt;/code>&lt;/pre>
</span><span class='line'>
</span><span class='line'>&lt;p></span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Now whenever a node with the FQDN nfs.example.lan syncs with the master it runs <code>/usr/local/bin/simple-enc.sh nfs.examle.lan.yaml</code>. This returns the contents of the YAML file above. The layout of it is pretty logical, but I suggest reading Puppetlabs <a href="http://docs.puppetlabs.com/guides/external_nodes.html">docs</a>.</p>

<p>How is this better than the previous Hiera setup? First I can now use my module with The Foreman which answers my immediate need. Second I can now submit this module to the Forge with a warm fuzzy feeling inside as I am a good citizen. not only does it work with Puppet 3, but also really old versions of Puppet that do not support an ENC or Hiera. It can do this because the user can still edit the class parameters directly, or set the in <code>site.pp</code> (<strong>DON'T DO THAT</strong>).</p>

<p>You can install the module on your own Puppet master with:</p>

<p>```
git clone http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs.git \</p>

<pre><code>/etc/puppet/modules/nfs/
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RHEL and CentOS joining forces]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces/"/>
    <updated>2014-01-08T14:34:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/3colCNj.png" width="200" height="200">Yesterday saw probably the biggest FLOSS news in recent times. Certainly the biggest news of 2014 so far :-) By some freak of overloaded RSS readers, I missed the announcement, but I did see this:</p>

<blockquote class="twitter-tweet" lang="en"><p>Day 1 at the new job. Important stuff first.. Where do I get my Red Hat ?</p>&mdash; Karanbir Singh (@CentOS) <a href="https://twitter.com/CentOS/statuses/420876286785892353">January 8, 2014</a></blockquote>


<script async src="http://www.chriscowley.me.uk//platform.twitter.com/widgets.js" charset="utf-8"></script>


<!-- more -->


<p>It did not take long to dig up <a href="http://community.redhat.com/centos-faq/?utm_content=buffer6403d&amp;utm_source=buffer&amp;utm_medium=twitter&amp;utm_campaign=Buffer">this</a> and <a href="http://lists.centos.org/pipermail/centos-announce/2014-January/020100.html">this</a>, where Red Hat and CentOS respectively announce that they have joined forces. Some things from the announcement struck me:</p>

<blockquote><p> Some of us now work for Red Hat, but not RHEL</p></blockquote>

<p>That is important! This says to me that Red Hat see the value of CentOS as an entity in itself. By not linking the CentOS developers to RHEL in anyway, they are not going to be side-tracking them. Instead, they are simple freeing them up to work more effectively on CentOS.</p>

<blockquote><p>we are now able to work with the Red Hat legal teams</p></blockquote>

<p>QA was always a problem for CentOS, simply because it took place effectively in secret. Now they can just walk down the corridor to talk to the lawyers who would have previously (potentially) sued them, all the potential problems go away.</p>

<h1>The RHEL Ecosystem</h1>

<p><span class='pullquote-right' data-pullquote='In Fedora things can break without people really worrying'>
In the beginning there is <a href="http://fedoraproject.org">Fedora</a>), where the RHEL developers get to play. Here is where they can try new things and make mistakes. In Fedora things can break without people really worrying (especially in Rawhide). The exception to this is my wife as we run it on the family PC and she gets quite frustrated with its foibles. However, she knew she was marrying a geek from the outset, so I will not accept any blame for this.
</span>}</p>

<p>Periodically, the the Fedora developers will pull everything together and create a release that has the potential to be transformed into RHEL. Here they pull together all the things that have be learnt over the last few releases. I consider this an Alpha release of RHEL. At this point, behind the scenes, the RHEL developers will take those packages and start work on the next release of RHEL.</p>

<p><span class='pullquote-right' data-pullquote='Red Hat as a company are built on Open Source'>
On release of RHEL, Red Hat make the source code available, as required by the terms of the GPL (and other relevant licenses).The thing is, Red Hat as a company are built on Open Source principles, they firmly believe in them and, best of all, they practise what the preach. They would still be within the letter of the law if the just dumped a bunch of apparently random scripts on a web server. Instead, they publish the SRPM packages used to build RHEL.
</span></p>

<p>CentOS then take these sources and get to work. By definition they are always beind RHEL. As many know this got pretty bad at one point:</p>

<p><img src="http://www.standalone-sysadmin.com/~matt/centos-delays.jpg" title="center" ></p>

<p>(Thanks to Matt Simmons, aka <a href="http://www.standalone-sysadmin.com">Standalone Sysadmin</a>, from whom I blatantly stole that graph, I'll ask permission later)</p>

<p>Since then, things have got better, with new point releases coming hot on the heels of RHEL. Certainly preparations for EL7 seemed to be going on nicely even before this announcement.</p>

<h1>how does this now affect the two projects</h1>

<p>Both CentOS and Red Hat have a lot to gain from this alliance. <img class="right" src="http://i.imgur.com/qbKvXko.jpg" width="350" height="350">I am sure that there are few people in the wider community who will be upset, but I think that it is a good thing. The reality is that CentOS and RHEL have never been enemies. The people that are using CentOS are just simply never going to pay Red Hat for support they do not need.</p>

<p>When I started at Snell (then Snell &amp; Wilcox), the official line was to use RHEL for all our Linux servers. They had everything paid up for a couple of years at the time. By the time renewal came around the global financial crisis had hit, we had used the support two or three times and each time I had solved the problem before Red Hat answered the ticket. So, we decided to switch to CentOS (which was trivial).</p>

<p>At the other end of the scale you have the web-scale people. For them, paying Red Hat for support is both unnecessary (they have the right people on staff) and prohibitively expensive. When you have tens of thousands of nodes you cannot use a licensing model that support each one.</p>

<p>In the cloud model you also have a problem, in that you are effectively renting an OS. Microsoft and Red Hat you have an administrative overhead of ensuring you have the right licenses available. In my experience Red Hat make it a lot easier, but it is an overhead none the less.</p>

<p>All three of these will get a huge benefit. Now that the CentOS developers are on staff at Red Hat they have direct access to the source code. There should no longer be any need to wait for RHEL to drop before they start building. Red Hat will be supplying infrastructure and community support, which will also be a massive bonus.</p>

<p>So what do Red Hat gain? In terms of new customers, they may get some of that first group. These are the people that may well do their testing with CentOS, but may now choose to go production with RHEL. I certainly would be more willing to now that XFS is not in a separate (expensive) RAN channel. I do not see the cloud or web-scale people changing to a paid support model. It will remain prohibitively expensive for them.</p>

<p>I think they biggest thing that Red Hat will gain is that get to give Oracle a good kicking. Oracle basically do the same thing as CentOS, but they stick a thumping great big support charge on it. To be honest I have never really worked out why anyone would use it. Yes they are cheaper than Red Hat, but not by much. A couple of years ago Red Hat took steps to <a href="http://www.theregister.co.uk/2011/03/04/red_hat_twarts_oracle_and_novell_with_change_to_source_code_packaging/">make life harder</a>. That had an unfortunate knock-on effect on CentOS, causing the huge delay in CentOS 6. Now CentOS should not have that problem as they are closer to source.</p>

<h1>TL;DR</h1>

<p>CentOS and RHEL joining forces is in my opinion a really good thing, with both parties getting significant benefits. Granted they are bit less tangible for Red Hat, but that does not make them any less significant.</p>

<p>Personally I am really excited to see what it is in store - especially from CentOS. I even have a couple of SIG ideas too.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integrating RHEL with Active Directory]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/12/16/integrating-rhel-with-active-directory/"/>
    <updated>2013-12-16T09:52:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/12/16/integrating-rhel-with-active-directory</id>
    <content type="html"><![CDATA[<p>I had a request on Reddit to share a document I wrote about connect Red Hat Enterprise Linux with Active Directory. The original document I wrote is confidential, but I said I would write it up.</p>

<p>This works for both Server 2008(R2) and 2012. If I recall correctly it will also work with 2003, but may need to minor terminology changes on the Windows side. From the Linux side, it should be fine with RHEL 6 and similar (CentOS and Scientific Linux). It should also apply to Fedora, but your mileage may vary.</p>

<!-- more -->


<p>So without further ado, let's dive in. To do this you need to know what is actually happening under the surface when you authenticate to AD from a client. The basic idea looks something like this:</p>

<p><img class="center" src="https://docs.google.com/drawings/d/1tjaacfXrTJtOZCREonoXzdHfgZQHssQ2zkDzFpLGeX0/pub?w=960&amp;h=720"></p>

<p>Integration with AD requires the installation of a few services in Red Hat, along with some minor modifications on the Windows Domain Controllers. On the Linux side, everything revolves around the System Security Services Daemon (SSSD). All communication between the PAM and the various possible back-ends is brokered through this daemon. This is only one solution, there are several. The others involve Winbind (which I have found problematic), or LDAP/Kerberos directly (no offline authentication, more difficult to set up). Note that this does not give you any file sharing, but  can easily be extended to do so using Samba.</p>

<p>PAM communicates with SSSD, which in turn talks to Active Directory via LDAP and Kerberos. Identification is performed via LDAP, with the user is authenticated using Kerberos. These different components have some prerequisites on Windows.</p>

<ul>
<li>DNS must be working fully - both forward and reverse lookups should be functional. If the Kerberos server (Windows Domain Controller) cannot identify the client via DNS, Kerberos will fail.</li>
<li>Accurate time is essential – if the two systems have too larger difference in time (about 5 minutes), Kerberos will fail.</li>
<li>The Active Directory needs to be extended to include the relevant information for *NIX systems (home directory, shell, UUID/GUID primarily).

<ul>
<li>They are actually there, but empty and uneditable. The necessary GUI fields are part of “Identity Management for UNIX”</li>
</ul>
</li>
<li>It must be possible for the Linux client to perform an LDAP search. This could be either via an anonymous bind or authenticated.

<ul>
<li>Anonymous is obviously not recommended.</li>
<li>Simple binds (username/password) do work but are not recommended. Although I am not one to practise what I preach (see below).</li>
<li>The best option is SASL/GSSAPI, using a keytab generated by Samba. This does not require Admin privileges on Windows, only permissions to join computers to the domain.</li>
</ul>
</li>
</ul>


<p>For both DNS and NTP I'm assuming that you are using the services provided by Active Directory. It is possible to break those out to other boxes, but it beyond my Windows Admin ability/desire to do so.</p>

<h1>Preparing Active Directory</h1>

<p>In Server Manager, add the Role Service "Identity Management for UNIX". This is under the Role "Active Directory Domain Services" (took me a while to find that). When it asks, use your AD domain name as the NIS name. For example, with a AD domain of <em>chriscowley.lab</em>, use <em>chriscowley</em>.</p>

<p>Once that is installed, create a pair of groups. For the sake of argument, lets call them <em>LinuxAdmin</em> and <em>LinuxUser</em>. The intended roles of these 2 groups is left as an exercise for the reader. When you create these groups, you will see a new tab in the properties window for both groups and users: "UNIX Attributes".</p>

<p>Now go ahead and create a user (or edit an existing one). Go into the UNIX tab and set the configure the user for UNIX access: <img class="right" src="http://i.imgur.com/Ox9kuAy.png"></p>

<ul>
<li>Select the NIS domain you created earlier</li>
<li>Set an approprate UUID (default should be fine)</li>
<li>Set the login shell as <code>/bin/bash</code>, <code>/bin/sh</code> should be fine most of the time, but I have seen a few odd things happen (details escape me)</li>
<li>Set the home directory. I seperate them out from local users to something like <code>/home/&lt;DOMAIN&gt;/&lt;username&gt;</code></li>
</ul>


<p>Open up one of your groups (let's start with LinuxAdmin) and add the user to that group. Note you have to do it 2 places (don't blame me, I am just the messenger). Both in the standard Groups tab, but also in the UNIX attributes tab.</p>

<p>That should be everything on the Windows side.</p>

<h1>Configure RHEL as a client</h1>

<p>Most of the heavy lifting is done by the <em>System Security Service Daemon</em> (SSSD).</p>

<p><code>
yum install sssd sssd-client krb5-workstation samba openldap-clients policycoreutils-python
</code></p>

<p>This should also pull in all the dependencies.</p>

<h2>Configure Kerberos</h2>

<p>I've already said, this but I will repeat myself as getting it wrong will cause many lost hours.</p>

<ul>
<li>DNS must be working for both forward and reverse lookups</li>
<li>Time must be in sync accross all the clients</li>
</ul>


<p>Make sure that /etc/resolv.conf contains your domain controllers.</p>

<p><strong>Gotcha</strong>: In RHEL/Fedora the DNS setting are defined in /etc/sysconfig/network-settings/ifcfg-eth0 (or whichever NIC comes first) by Anaconda. This will over-write /etc/resolv.conf on reboot. For no good reason other than stubbornness I tend to remove these entries and define resolv.conf myself (or via configuration management). Alternatively put DNS1 and DNS2 entries in the network configuration files.</p>

<p>In <code>/etc/krb5.conf</code> change you servers to point at your Domain Controllers.</p>

<p>```
[logging]
 default = FILE:/var/log/krb5libs.log</p>

<p>[libdefaults]
 default_realm = AD.EXAMPLE.COM
 dns_lookup_realm = true
 dns_lookup_kdc = true
 ticket_lifetime = 24h
 renew_lifetime = 7d
 rdns = false
 forwardable = yes</p>

<p>[realms]
 AD.EXAMPLE.COM = {
  # Define the server only if DNS lookups are not working</p>

<h1>kdc = server.ad.example.com</h1>

<h1>admin_server = server.ad.example.com</h1>

<p> }</p>

<p>[domain_realm]
 .ad.example.com = AD.EXAMPLE.COM
 ad.example.com = AD.EXAMPLE.COM
```</p>

<p>You should now be able to run:</p>

<p><code>
kinit aduser@AD.EXAMPLE.COM
</code></p>

<p>That should obtain a kerberos ticket (check with <code>klist</code>) and you can move on. If it does not work fix it now - Kerberos is horrible to debug later.</p>

<h2>Enable LDAP Searches</h2>

<p>The best way to bind to AD is using SASL/GSSAPI as no passwords are needed.</p>

<p><code>
kinit Administrator@AD.EXAMPLE.COM
net ads join createupn=host/client.ad.example.com@AD.EXAMPLE.COM –k
net ads keytab create   
net ads keytab add host/client.ad.example.com@AD.EXAMPLE.COM
</code></p>

<p>You should now be able to get information about yourself from AD using ldapsearch:
<code>
ldapsearch -H ldap://server.ad.example.com/ -Y GSSAPI -N -b "dc=ad,dc=example,dc=com" "(&amp;(objectClass=user)(sAMAccountName=aduser))"
</code></p>

<h2>Configure SSSD</h2>

<p>Everything in SSSD revolves around a single config file (/etc/sssd/ssd.conf).</p>

<p>```
[sssd]
 config_file_version = 2
 domains = ad.example.com
 services = nss, pam
 debug_level = 0</p>

<p>[nss]</p>

<p>[pam]</p>

<p>[domain/ad.example.com]
 id_provider = ldap
 auth_provider = krb5
 chpass_provider = krb5
 access_provider = ldap</p>

<p> # To use Kerberos, un comment the next line
 #ldap_sasl_mech = GSSAPI</p>

<p> # The following 3 lines bind to AD. Comment them out to use Kerberos
 ldap_default_bind_dn = CN=svc_unix,OU=useraccounts,DC=ad,DC=example,DC=com
 ldap_default_authtok_type = password
 ldap_default_authtok = Welcome_2014</p>

<p> ldap_schema = rfc2307bis</p>

<p> ldap_user_search_base = ,dc=ad,dc=example,dc=com
 ldap_user_object_class = user</p>

<p> ldap_user_home_directory = unixHomeDirectory
 ldap_user_principal = userPrincipalName</p>

<p> ldap_group_search_base = ou=groups,dc=ad,dc=example,dc=com
 ldap_group_object_class = group</p>

<p> ldap_access_order = expire
 ldap_account_expire_policy = ad
 ldap_force_upper_case_realm = true</p>

<p> krb5_realm = AD.EXAMPLE.COM
```</p>

<p>There is something wrong here. Note the lines:
```
 # To use Kerberos, un comment the next line
 #ldap_sasl_mech = GSSAPI</p>

<p> # The following 3 lines bind to AD. Comment them out to use Kerberos
 ldap_default_bind_dn = CN=svc_unix,OU=useraccounts,DC=ad,DC=example,DC=com
 ldap_default_authtok_type = password
 ldap_default_authtok = Welcome_2014
```</p>

<p>Instead of doing the SASL/GSSAPI bind I would prefer to do I have chickened out and done a simple bind. Why? Because I am weak... :-(</p>

<p>Try with kerberos first, if it works then awesome, if not then create a service account in AD that can do nothing other than perform a search and use that to perform the bind. Make sure its path matches that of the <em>ldap_default_bind_dn</em> path, also make sure the password is more complex than "Welcome_2014".</p>

<p>For now this does nothing, we need to tell PAM to use it. The easiest way to enable this on RHEL is to use the authconfig command:</p>

<p><code>
authconfig --enablesssd --enablesssdauth --enablemkhomedir –update
</code></p>

<p>This will update <code>/etc/nsswitch.conf</code> and various files in <code>/etc/pam.d</code> to tell the system to authenticate against SSSD. SSSD will in turn talk to Active Directory, using LDAP for Identification and Kerberos for authentication.
Finally you can enable your LinuxAdmin’s to use sudo. Run the command visudo and add the line:</p>

<p>```
%LinuxAdmin ALL=(ALL)       ALL</p>

<h1>note the % sign, the defines it as a group not a user</h1>

<p>```</p>

<p>Now your admin’s can run commands as root by prefacing them with sudo. For an encore, I would suggest disabling root login via SSH. Log in as your AD user (leave your root session open, just in case) and run:</p>

<p><code>
sudo sed -i 's/PermitRootLogin no/PermitRootLogin yes/' /etc/ssh/sshd_config
sudo service sshd reload
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Connect to Fedora 19 with FreeNX]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/08/01/connect-to-fedora-19-with-freenx/"/>
    <updated>2013-08-01T10:17:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/08/01/connect-to-fedora-19-with-freenx</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/Z8LFhPUl.png" width="400" height="250"> FreeNX is a great remote desktop protocol. I find it more responsive than VNC and it uses less bandwidth. The biggest advantage though (in my eyes) is that it uses SSH to do the authentication. With VNC, each user has to arrange another password to connect to their VNC session.</p>

<!-- more -->


<p>However, FreeNX is still not really working nicely with GNOME 3. If you use KDE you are fine, but I like GNOME and many of the programs are GTK as a result. This means that they look out of place on KDE, which causes my engineer OCD super-sensory powers to go mad.</p>

<p>My workaround is to effectively go back to the tried and tested Gnome 2 environment, nowadays know as MATE.</p>

<p>Get the server installed and configured along with the MATE desktop:</p>

<p><code>
sudo yum -y groupinstall "MATE desktop"
sudo yum -y install freenx-server
sudo /usr/libexec/nx/nxsetup --install --setup-nomachine-key
sudo chkconfig freenx-server on
</code></p>

<p>Now open <code>/etc/nxserver/node.conf</code> and un-comment the line that sets the <code>COMMAND_START_GNOME</code> variable. You need to edit this line to read:</p>

<p><code>
COMMAND_START_GNOME=mate-session
</code></p>

<p>and restart the server with <code>sudo service freenx-server restart</code></p>

<p>Now connect to it using the NX client and chose to use a unix-gnome desktop. Instead of firing up <code>gnome-session</code> (which will fail) it will now run <code>mate-session</code> and you are happy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bamboo Invoice on Centos with Nginx]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/04/29/bamboo-invoice-on-centos-with-nginx/"/>
    <updated>2013-04-29T21:16:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/04/29/bamboo-invoice-on-centos-with-nginx</id>
    <content type="html"><![CDATA[<p><a href="http://www.bambooinvoice.org/">BambooInvoice</a> is free Open Source invoicing software intended for small businesses and independent contractors. It is easy to use and creates pretty good looking invoices.</p>

<!-- more -->


<p>It is a simple PHP application that is based on the CodeIgniter framework. This means it is really simple to install on a typically LAMP stack. I however use Nginx and could not find any notes on how to configure it. It is pretty typical you can get most of the way by reading any of the Nginx howto documents on the web. Personally, for PHP apps, I use PHP-FPM, so you could use <a href="http://www.howtoforge.com/installing-nginx-with-php5-and-php-fpm-and-mysql-support-on-centos-6.4">this on Howtoforge</a> to get most of the way. That will get you a working Nginx, PHP and MySQL system.</p>

<p>Download the install file from [http://bambooinvoice.org/] an unzip is in your www folder:</p>

<p><code>bash
cd /var/www
wget http://bambooinvoice.org/img/bambooinvoice_089.zip
unzip bambooinvoice_089.zip
</code></p>

<p>You next step is to create a database for it along with a user:</p>

<p><code>mysql
CREATE DATABASE bambooinvoice DEFAULT CHARACTER SET utf8;
GRANT ALL ON bambooinvoice.* TO 'bambooinvoice'@'localhost' IDENTIFIED BY 'bambooinvoice';
FLUSH PRIVILEGES;
exit
</code></p>

<p>Now you can edit the config files to point at the database:</p>

<p>```php /var/www/bambooinvoices/bamboo_system_files/application/config/database.php
&lt;?php  if (!defined('BASEPATH')) exit('No direct script access allowed');
$active_group = 'default';</p>

<p>$db['default']['hostname'] = 'localhost';
$db['default']['username'] = 'bambooinvoice';
$db['default']['password'] = 'bambooinvoice';
$db['default']['database'] = 'bambooinvoice';
$db['default']['dbdriver'] = 'mysql';
$db['default']['dbprefix'] = 'bamboo_';
$db['default']['active_r'] = TRUE;
$db['default']['pconnect'] = FALSE;
$db['default']['db_debug'] = TRUE;
$db['default']['cache_on'] = FALSE;
$db['default']['cachedir'] = '';
$db['default']['char_set'] = 'utf8';
$db['default']['dbcollat'] = 'utf8_general_ci';
?>
```</p>

<p>Next you need set the base_url in <code>/var/www/bambooinvoices/bamboo_system_files/application/config/config.php</code>. Nothing else is essential in that file, but read the docs in the ZIP file to see what else you want to change.</p>

<p>Now the all important bit.</p>

<p>```nginx /etc/nginx/conf.d/bamboo.conf
server {</p>

<pre><code>listen 80;
server_name bamboo.example;
root /var/www/bambooinvoice/;
index index.php index.html;
access_log              /var/log/nginx/bamboo_access.log;
error_log               /var/log/nginx/bamboo_error.log;

location = /robots.txt {
    allow all;
    log_not_found off;
    access_log off;
}


# Deny all attempts to access hidden files such as .htaccess, .htpasswd, .DS_Store (Mac).
location ~ /\. {
    deny all;
    access_log off;
    log_not_found off;
 }
 location / {
     try_files $uri $uri/ /index.php$request_uri /index.php;
 }


 location ~ \.php($|/) {
     try_files $uri =404;
     fastcgi_pass 127.0.0.1:9000;
     include /etc/nginx/fastcgi_params;
     fastcgi_index index.php;
     set $script $uri;
     set $path_info "";
     if ($uri ~ "^(.+\.php)(/.+)") {
         set $script $1;
         set $path_info $2;
     }
     fastcgi_param URI $uri;
     # Next two lines are fix the 502 (Bad gateway) error
     fastcgi_buffers 8 16k;
     fastcgi_buffer_size 32k;

     fastcgi_param PATH_INFO $path_info;
     fastcgi_param SCRIPT_NAME $script;
     fastcgi_param SCRIPT_FILENAME $document_root$script;
  }
</code></pre>

<p>}
```</p>

<p>At first glance, there is nothing out of the ordinary. This is pretty much what Howtoforge gives you. Look more closely and I have added the 3 lines 39-41. This solves a gateway problem I had when creating a client.</p>
]]></content>
  </entry>
  
</feed>
