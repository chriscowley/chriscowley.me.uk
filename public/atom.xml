<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Just Another Linux Blog]]></title>
  <link href="http://www.chriscowley.me.uk/atom.xml" rel="self"/>
  <link href="http://www.chriscowley.me.uk/"/>
  <updated>2014-07-28T11:06:53+02:00</updated>
  <id>http://www.chriscowley.me.uk/</id>
  <author>
    <name><![CDATA[Chris Cowley]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Install Microsoft TrueType fonts on Fedora]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/07/28/install-microsoft-truetype-fonts-on-fedora/"/>
    <updated>2014-07-28T11:01:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/07/28/install-microsoft-truetype-fonts-on-fedora</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/IVNu1pf.png"> Fedora do nogt bundle Microsoft&#8217;s core Truetype fonts for licensing reasons. Normallly I do not care, personally I prefer <a href="https://fedorahosted.org/liberation-fonts/">Liberation fonts</a> anyway. However, today I needed to Verdana.</p>

<!-- more -->


<p>Traditionally, the way to install these on RPM based distributions has been:</p>

<ol>
<li>Grab the RPM spec file</li>
<li>Build an RPM from the spec file</li>
<li>Install RPM using the <code>rpm</code> command.</li>
</ol>


<p>All well and good, however there are a couple of problems.</p>

<ul>
<li>Using RPM directly is frowned upon</li>
</ul>


<p>Nowadays, Yum does various bits of house keeping in addition to RPM, so this can lead to the <code>rpm</code> and <code>yum</code> databases getting their knickers in a twist.</p>

<p>I get around this with a simple piece of <code>sed</code>/<code>grep</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://corefonts.sourceforge.net/msttcorefonts-2.0-1.spec | grep -v 'Prereq: /usr/sbin/chkfontpath' &gt; msttcorefonts-2.0-1.spec</span></code></pre></td></tr></table></div></figure>


<p>Now you can do all the usual stuff:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rpmbuild -ba msttcorefonts-2.0-1.spec
</span><span class='line'>yum --nogpgcheck ~/rpmbuild/RPMS/noarch/msttcorefonts-2.0-1.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<p>Relogin and you will have access to Microsoft&#8217;s fonts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Super Slick Agile Puppet for Devops]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/06/25/super-slick-agile-puppet-for-devops/"/>
    <updated>2014-06-25T21:22:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/06/25/super-slick-agile-puppet-for-devops</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/3SJXbMb.jpg">With a superb buzzword laden title like that, then I reckon massive traffic boost is inevitable.</p>

<p>Puppet is my favourite Configuration Management tool. This is not a post to try and persuade anyone not to use Ansible, Chef or any other. What I want to do is show I build Puppet based infrastuctures in such away that it meets all the basic tenets of DevOps/Agile/buzzword-of-the-month.</p>

<!-- more -->


<p>What to we need:</p>

<ul>
<li>CentOS 6 - RHEL/CentOS is pretty much the defacto enterprise distro. This will easily translate to Debian/Ubuntu or anything else.</li>
<li>Puppet 3 - I like a traditional Master/Agent set up, if you prefer master-less good for you. This is my blog, my rules.</li>
<li>Git</li>
<li>Dynamic Environments</li>
<li>PuppetDB</li>
<li>Hiera</li>
<li>Jenkins</li>
</ul>


<p>All the config is stored in Git, with Jenkins watching it.</p>

<p>Puppet tends to fall apart pretty quickly if you do not have DNS in place. You can start using host files, but that will get old quickly. Ideally, the first thing you will do with Puppet is install a DNS server managed by Puppet. Maybe that will be the next post.</p>

<h1>Puppet</h1>

<p>Starting with a base Centos 6 install, the installation is very easy:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum -y install http://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm
</span><span class='line'>yum -y install puppet puppet-server rubygem-activerecord</span></code></pre></td></tr></table></div></figure>


<p>Our environments need a place to go, so create that:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir /etc/puppet/environments
</span><span class='line'>chgrp puppet /etc/puppet/environments
</span><span class='line'>chmod 2775 /etc/puppet/environments</span></code></pre></td></tr></table></div></figure>


<p>The configuration will look like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[main]
</span><span class='line'>    logdir = /var/log/puppet
</span><span class='line'>    rundir = /var/run/puppet
</span><span class='line'>    ssldir = $vardir/ssl
</span><span class='line'>    trusted_node_data = true
</span><span class='line'>    pluginsync = true
</span><span class='line'>    
</span><span class='line'>[agent]
</span><span class='line'>    classfile = $vardir/classes.txt
</span><span class='line'>    localconfig = $vardir/localconfig
</span><span class='line'>    report = true
</span><span class='line'>    environment = production
</span><span class='line'>    ca_server = puppet.chriscowley.lan
</span><span class='line'>    server = puppet.chriscowley.lan
</span><span class='line'>    
</span><span class='line'>[master]
</span><span class='line'>    environmentpath = $confdir/environments
</span><span class='line'>    # Passenger
</span><span class='line'>    ssl_client_header        = SSL_CLIENT_S_DN
</span><span class='line'>    ssl_client_verify_header = SSL_CLIENT_VERIFY</span></code></pre></td></tr></table></div></figure>


<p>Do not use the Puppetmaster service. It uses Webrick, which is bad. Any more than 5 agents and it will start slowing down. Puppet is a RoR app, so stick it behind <a href="http://docs.puppetlabs.com/guides/passenger.html">Apache/Passenger</a>. We installed the <code>puppet-server</code> package for a simple reason: when you start it the first time, it will create your SSL certificates automatically. After that initial start you can stop it and forget it ever existed. So just run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service puppetmaster start
</span><span class='line'>service puppetmaster stop</span></code></pre></td></tr></table></div></figure>


<p>Unfortunately, you will need to put SELinux into Permissive mode temporarily. Once you have fired it up you can <a href="http://wiki.centos.org/HowTos/SELinux#head-faa96b3fdd922004cdb988c1989e56191c257c01">build a local policy</a> and re-enable it.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install httpd httpd-devel mod_ssl ruby-devel rubygems gcc gcc-c++ curl-devel openssl-devel zlib-devel
</span><span class='line'>gem install rack passenger
</span><span class='line'>passenger-install-apache2-module</span></code></pre></td></tr></table></div></figure>


<p>Next you need to configure Apache to serve up the RoR app.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -p /usr/share/puppet/rack/puppetmasterd
</span><span class='line'>mkdir /usr/share/puppet/rack/puppetmasterd/public /usr/share/puppet/rack/puppetmasterd/tmp
</span><span class='line'>cp /usr/share/puppet/ext/rack/config.ru /usr/share/puppet/rack/puppetmasterd/
</span><span class='line'>chown puppet:puppet /usr/share/puppet/rack/puppetmasterd/config.ru
</span><span class='line'>https://gist.githubusercontent.com/chriscowley/00e75ee021ce314fab1e/raw/c87abc38182eafc6d22a80d13078ac044fdde49f/puppetmaster.conf | sed 's/puppet-server.example.com/puppet.yourlan.lan/g'</span></code></pre></td></tr></table></div></figure>


<p>You will need to modify the <code>sed</code> command in the last line to match your environment.</p>

<p>You may also need to change the Passenger paths to match what the output of <code>passenger-install-apache2-module</code> told you. It is up to date as of the time of writing.</p>

<h1>Hiera</h1>

<p>Your config file (<code>/etc/puppet/hiera.yaml</code>) will already be created, mine looks like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>---
</span><span class='line'>:backends:
</span><span class='line'>  - yaml
</span><span class='line'>:hierarchy:
</span><span class='line'>  - defaults
</span><span class='line'>  - "nodes/%{clientcert}"
</span><span class='line'>  - "virtual/%{::virtual}"
</span><span class='line'>  - "%{environment}"
</span><span class='line'>  - "%{::osfamily}"
</span><span class='line'>  - global
</span><span class='line'>
</span><span class='line'>:yaml:
</span><span class='line'>  :datadir: "/etc/puppet/environments/%{::environment}/hieradata"</span></code></pre></td></tr></table></div></figure>


<p>There is also an <code>/etc/hiera.yaml</code> which Puppet does not use. change this to a symbolic link to avoid confusion.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ln -svf /etc/puppet/hiera.yaml /etc/hiera.yaml</span></code></pre></td></tr></table></div></figure>


<p>If you were to test it now, you will see a few errors:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Info: Retrieving pluginfacts
</span><span class='line'>Error: /File[/var/lib/puppet/facts.d]: Could not evaluate: Could not retrieve information from environment production source(s) puppet://puppet/pluginfacts
</span><span class='line'>Info: Retrieving plugin
</span><span class='line'>Error: /File[/var/lib/puppet/lib]: Could not evaluate: Could not retrieve information from environment production source(s) puppet://puppet/plugins</span></code></pre></td></tr></table></div></figure>


<p>Don&#8217;t worry about that for now, the important thing is that the agent connects to the master. If that happens the master does return an HTTP error, then you are good.</p>

<h1>R10k</h1>

<p>This is the tool I use to manage my modules. It can pull them off the Forge, or from wherever you tell it too. Most often that will be Github, or an internal Git repo if that&#8217;s what you use.</p>

<p>You need to install it from Ruby Gems, then there is a little configuration to do.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>gem install r10k
</span><span class='line'>mkdir /var/cache/r10k
</span><span class='line'>chgrp puppet /var/cache/r10k
</span><span class='line'>chmod 2775 /var/cache/r10k</span></code></pre></td></tr></table></div></figure>


<p>The file <code>/etc/r10k.yaml</code> should contain:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># location for cached repos
</span><span class='line'>:cachedir: '/var/cache/r10k'
</span><span class='line'>
</span><span class='line'># git repositories containing environments
</span><span class='line'>:sources:
</span><span class='line'>  :base:
</span><span class='line'>    remote: '/srv/puppet.git'
</span><span class='line'>    basedir: '/etc/puppet/environments'
</span><span class='line'>
</span><span class='line'># purge non-existing environments found here
</span><span class='line'>:purgedirs:
</span><span class='line'>  - '/etc/puppet/environments'</span></code></pre></td></tr></table></div></figure>


<h1>Git</h1>

<p>The core of your this process is the ubiquitous Git.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install git</span></code></pre></td></tr></table></div></figure>


<p>You need a Git repo to store everything, and also launch a deploy script when you push to it. To start with we&#8217;ll put it on the Puppet server. In the future I would put this on a dedicated machine, have Jenkins run tests, then run the deploy script on success.</p>

<p>However, it is not a standard repository, so you cannot just run <code>git init</code>. It needs:</p>

<ul>
<li>To be <strong>bare</strong></li>
<li>To be <strong>shared</strong></li>
<li>Have the <strong>master</strong> branch renamed to <strong>production</strong></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -pv /srv/puppet.git
</span><span class='line'>git init --bare --shared=group /srv/puppet.git
</span><span class='line'>chgrp -R puppet /srv/puppet.git
</span><span class='line'>cd /srv/puppet.git
</span><span class='line'>git symbolic-ref HEAD refs/heads/production</span></code></pre></td></tr></table></div></figure>


<p>Continuing to work as root is not acceptable, so create user (if you do not already have one).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>useradd &lt;username&gt;
</span><span class='line'>usermod -G wheel,puppet &lt;username&gt;
</span><span class='line'>visudo</span></code></pre></td></tr></table></div></figure>


<p>Uncomment the line that reads:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>%wheel        ALL=(ALL)       ALL</span></code></pre></td></tr></table></div></figure>


<p>This gives your user full <code>sudo</code> privileges.</p>

<h1>Deploy script</h1>

<p>This is what does the magic stuff. It needs to be <code>/srv/puppet.git/hooks/post-receive</code> so that it runs when you push something to this repository.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/bash
</span><span class='line'>
</span><span class='line'>umask 0002
</span><span class='line'>
</span><span class='line'>while read oldrev newrev ref
</span><span class='line'>do
</span><span class='line'>    branch=$(echo $ref | cut -d/ -f3)
</span><span class='line'>    echo
</span><span class='line'>    echo "--&gt; Deploying ${branch}..."
</span><span class='line'>    echo
</span><span class='line'>    r10k deploy environment $branch -p
</span><span class='line'>    # sometimes r10k gets permissions wrong too
</span><span class='line'>    find /etc/puppet/environments/$branch/modules -type d -exec chmod 2775 {} \; 2&gt; /dev/null
</span><span class='line'>    find /etc/puppet/environments/$branch/modules -type f -exec chmod 664 {} \; 2&gt; /dev/null
</span><span class='line'>done</span></code></pre></td></tr></table></div></figure>


<p>Run <code>chmod 0775 /srv/puppet.git/hooks/post-receive</code> to make is executable and writable by anyone in the <code>puppet</code> group.</p>

<h1>The first environment</h1>

<p>Switch to your user</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>su - &lt;username&gt;</span></code></pre></td></tr></table></div></figure>


<p>Clone the repository and create the necessary folder structure:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone /srv/puppet.git
</span><span class='line'>cd puppet
</span><span class='line'>mkdir -pv hieradata/nodes manifests site</span></code></pre></td></tr></table></div></figure>


<p>Now you can create <code>PuppetFile</code> in the root of that repository. This is what tells R10k what modules to deploy.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Puppet Forge
</span><span class='line'>mod 'puppetlabs/ntp', '3.0.0-rc1'
</span><span class='line'>mod 'puppetlabs/puppetdb', '3.0.1'
</span><span class='line'>mod 'puppetlabs/stdlib', '3.2.1'
</span><span class='line'>mod 'puppetlabs/concat', '1.0.0'
</span><span class='line'>mod 'puppetlabs/inifile', '1.0.3'
</span><span class='line'>mod 'puppetlabs/postgresql', '3.3.3'
</span><span class='line'>mod 'puppetlabs/firewall', '1.0.2'
</span><span class='line'>mod 'chriscowley/yumrepos', '0.0.2'
</span><span class='line'>
</span><span class='line'># Get a module from Github
</span><span class='line'>#mod 'custom',
</span><span class='line'>#  :git =&gt; 'https://github.com/chriscowley/puppet-pydio.git',
</span><span class='line'>#  :ref =&gt; 'master'</span></code></pre></td></tr></table></div></figure>


<p>A common error I make if I am not looking properly is to put the SSH URL from Github in there. This will not work unless you have added your SSH key on the Puppet server. Better just to put the HTTPS URL in there, there is need to write back to it after all.</p>

<p>Next you need to tell Puppet what agents should get what. To begin with, everything will get NTP, but only the Puppetmaster will get PuppetDB. To that end create <code>hieradata/common.yaml</code> with this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>---
</span><span class='line'>classes:
</span><span class='line'>  - ntp
</span><span class='line'>
</span><span class='line'>ntp::servers:
</span><span class='line'>  - 0.pool.ntp.org
</span><span class='line'>  - 1.pool.ntp.org
</span><span class='line'>  - 2.pool.ntp.org
</span><span class='line'>  - 3.pool.ntp.org</span></code></pre></td></tr></table></div></figure>


<p>Next create <code>hieradata/nodes/$(hostname -s).yaml</code> with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>---
</span><span class='line'>classes:
</span><span class='line'>  - puppetdb
</span><span class='line'>  - puppetdb::master::config</span></code></pre></td></tr></table></div></figure>


<p>Finally, you need to tell Puppet to get the data from Hiera. Create <code>manifests.site.pp</code> with</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hiera_include('classes')</span></code></pre></td></tr></table></div></figure>


<p>You should need nothing else.</p>

<p>Now you can push it to the master repository.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git add .
</span><span class='line'>git commit -a -m "Initial commit"
</span><span class='line'>git branch -m production
</span><span class='line'>git push origin production</span></code></pre></td></tr></table></div></figure>


<h1>Testing</h1>

<p>Of course, the whole point of all this is that we do as much testing as we can before any sort of deploy. We also want to keep our Git repository nice clean (especially if you push it to Github), so if we can avoid commits with stupid errors that would be great.</p>

<p>To perform your testing you need to replicate your production environment. From now on, I&#8217;m going to assume that you are working on your own workstation.</p>

<p>Clone your repository:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone ssh://&lt;username&gt;@puppet.example.com/srv/puppet.git
</span><span class='line'>cd puppet</span></code></pre></td></tr></table></div></figure>


<p>To perform all the testing, <a href="http://rvm.io/">RVM</a> is your friend. This allows you to replicate the ruby environment on the master, have all the necessary gems installed in a contained environment and sets you up to integrate with Jenkins later. Install is with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -sSL https://get.rvm.io | bash -s stable</span></code></pre></td></tr></table></div></figure>


<p>Follow any instructions it gives your, then you can create your environment. This will be using a old version of ruby as we are running CentOS 6 on the master.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rvm install ruby-1.8.7
</span><span class='line'>rvm use ruby-1.8.7
</span><span class='line'>rvm gemset create puppet
</span><span class='line'>rvm gemset use puppet
</span><span class='line'>rvm --create use ruby-1.8.7-head@puppet --rvmrc</span></code></pre></td></tr></table></div></figure>


<p>Create a Gemfile that contains:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>source 'https://rubygems.org'
</span><span class='line'> 
</span><span class='line'>gem 'puppet-lint', '0.3.2'
</span><span class='line'>gem 'puppet', '3.6.2'
</span><span class='line'>gem 'kwalify', '0.7.2'</span></code></pre></td></tr></table></div></figure>


<p>Now you can install the gems with <code>bundle install</code>.</p>

<p>The tests will be run by a pre-commit hook script, that looks something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/bash
</span><span class='line'># pre-commit git hook to check the validity of a puppet main manifest
</span><span class='line'>#
</span><span class='line'># Prerequisites:
</span><span class='line'># gem install puppet-lint puppet
</span><span class='line'>#
</span><span class='line'># Install:
</span><span class='line'># /path/to/repo/.git/hooks/pre-commit
</span><span class='line'>#
</span><span class='line'># Authors:
</span><span class='line'># Chris Cowley &lt;chris@chriscowley.me.uk&gt;
</span><span class='line'>
</span><span class='line'>echo "Checking style"
</span><span class='line'>for file in `git diff --name-only --cached | grep -E '\.(pp)'`; do
</span><span class='line'>  puppet-lint ${file}
</span><span class='line'>  if [ $? -ne 0 ]; then
</span><span class='line'>    style_bad=1
</span><span class='line'>  else
</span><span class='line'>    echo "Style looks good"
</span><span class='line'>  fi
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>echo "Checking syntax"
</span><span class='line'>for file in `git diff --name-only --cached | grep -E '\.(pp)'`; do
</span><span class='line'>  puppet parser validate $file
</span><span class='line'>  if [ $? -ne 0 ]; then
</span><span class='line'>    syntax_bad=1
</span><span class='line'>    echo "Syntax error in ${file}"
</span><span class='line'>  else
</span><span class='line'>    echo "Syntax looks good"
</span><span class='line'>  fi
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>for file in `git diff --name-only --cached | grep -E '\.(yaml)'`; do
</span><span class='line'>  echo "Checking YAML is valid"
</span><span class='line'>  ruby -e "require 'yaml'; YAML.parse(File.open('$file'))"
</span><span class='line'>  if [ $? -ne 0 ]; then
</span><span class='line'>    yaml_bad=1
</span><span class='line'>  else
</span><span class='line'>    echo "YAML looks good"
</span><span class='line'>  fi
</span><span class='line'>done
</span><span class='line'>
</span><span class='line'>if [ ${yaml_bad}  ];then
</span><span class='line'>  exit 1
</span><span class='line'>elif [ ${syntax_bad}  ]; then
</span><span class='line'>  exit 1
</span><span class='line'>elif [ ${style_bad}  ]; then
</span><span class='line'>  exit 1
</span><span class='line'>else
</span><span class='line'>  exit 0
</span><span class='line'>fi
</span></code></pre></td></tr></table></div></figure>


<p>This should set you up very nicely. Your environments are completely dynamic, you have a framework in place for testing.</p>

<p>For now the deployment is with a hook script, but that is not the ultimate goal. This Git repo needs to be on the Puppet master. You may well already have a Git server you want to use. TO this end, in a later post I will be add Jenkins into the mix. As you are running the tests in an RVM environment, it will be very easy to put into Jenkins. This can then perform the deployment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Linux Active Directory Integration]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/06/17/new-linux-active-directory-integration/"/>
    <updated>2014-06-17T10:28:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/06/17/new-linux-active-directory-integration</id>
    <content type="html"><![CDATA[<p>This used to be quite complex, but now is astoundingly simple. Now there is a new project call <a href="http://freedesktop.org/software/realmd/">realmd</a>. It is in recent version of Debian (Jessie and Sid) and Ubuntu (since 13.04). For Red Hat types, it is RHEL7 and Fedora (since 18).</p>

<!-- more -->


<p>If you&#8217;re on Debian/Ubuntu, install with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apt-get install realmd</span></code></pre></td></tr></table></div></figure>


<p>For RHEL/Fedora:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo yum install realmd</span></code></pre></td></tr></table></div></figure>


<p>Now you can go ahead and join the domain:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo realm join --user=&lt;admin-user&gt; example.com</span></code></pre></td></tr></table></div></figure>


<p>That is it, you can check this by running <code>sudo realm list</code>, which will give you something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>example.com
</span><span class='line'>  type: kerberos
</span><span class='line'>  realm-name: EXAMPLE.COM
</span><span class='line'>  domain-name: example.com
</span><span class='line'>  configured: kerberos-member
</span><span class='line'>  server-software: active-directory
</span><span class='line'>  client-software: sssd
</span><span class='line'>  required-package: oddjob
</span><span class='line'>  required-package: oddjob-mkhomedir
</span><span class='line'>  required-package: sssd
</span><span class='line'>  required-package: adcli
</span><span class='line'>  required-package: samba-common
</span><span class='line'>  login-formats: %U@example.com
</span><span class='line'>  login-policy: allow-realm-logins</span></code></pre></td></tr></table></div></figure>


<p>The last step is <code>sudo</code>. If you want to have everyone in <em>Domain Admins</em> have permission to run everything as root, then add the following to <code>sudoers</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>%domain\ admins@example.com ALL=(ALL)       ALL</span></code></pre></td></tr></table></div></figure>


<p>By default <code>realmd</code> used SSSD to perform the authentication. This in turn configures Kerberos and LDAP.</p>

<p>My initial testing has been performed with an Active Directory that has &#8220;Identity Managment for UNIX&#8221; installed. However, I forgot to actually enable my user for UNIX. Even so, it worked perfectly. It sees my Windows groups and defines a home directory of <code>/home/example.com/&lt;username&gt;</code>. I am pretty certain that you do not need to extend AD, it should work out of the box from what I can see.</p>

<p>As a bonus, it seems to respect nested groups, something that has always been a bug bear in these things.</p>

<h2>Edit (18/6/2014)</h2>

<p>It has been bought to my attention that there is dependency problems in Ubuntu 14.04. The <a href="http://funwithlinux.net/2014/04/join-ubuntu-14-04-to-active-directory-domain-using-realmd">work around</a> is to not let <code>realm</code> install the dependencies. To <code>/etc/realmd.conf</code> add:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[service]
</span><span class='line'>automatic-install = no</span></code></pre></td></tr></table></div></figure>


<p>Now you need to install the necessary packages yourself:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt install samba-common-bin, samba-libs sssd-tools krb5-user adcli</span></code></pre></td></tr></table></div></figure>


<p>You will need to enter your kerberos domain (e.g. EXAMPLE.COM) during the install. You should be able to get a ticket and join the domain.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Home-made Energy Bars]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/05/10/home-made-energy-bars/"/>
    <updated>2014-05-10T11:57:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/05/10/home-made-energy-bars</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/RUF1L6e.jpg" width="200">A break from computing today and into the world of nutrition. Cyclists love to talk about nutrition as the nature of our sport makes it a major consideration. I do not really know of any other sport where your fuel gives out before the rest of your body.</p>

<!-- more -->


<p>This means that cycling nutrition is big business, and expensive. A typical box of energy bars will cost about 1 euro a bar from a big box pusher, more from your LBS. To that end (as I like baking) I decided to make my own.</p>

<h1>Ingredients</h1>

<p>There is not much to it:</p>

<ul>
<li>200g sugar</li>
<li>120ml oil</li>
<li>2 tablespoons honey</li>
<li>225g porridge oats</li>
<li>250g fruit/nut mix</li>
</ul>


<p>Obviously the quality of these ingredients is all important. With the amount you are saving compared to a commercial bar, one can afford to splash out here. I use:</p>

<ul>
<li>Unrefined sugar</li>
<li>Good quality sunflower oil</li>
<li>Organic honey from a local producer</li>
<li>Good quality, thick rolled oats</li>
</ul>


<p>For the fruit and nut mix you can do whatever you want. We eat a lot of these and get them from a local organic produce shop. I just raid the kitchen draws and see what I come up with. The latest batch had:</p>

<ul>
<li>dried banana</li>
<li>raisins</li>
<li>sultanas</li>
<li>coconut</li>
<li>cranberries</li>
</ul>


<h1>Recipe</h1>

<p>You will need a decent sized saucepan as you&#8217;ll do all the mixing on the hob. Pre-heat the oven to 180ᵒC (350ᵒF/gas mark 4 I believe).</p>

<p>Start by gently melting together the sugar, oil and honey over a low heat. Be patient, this will take a while.</p>

<p>Add you fruit/nut mix and mix it all in thouroughly. At this point you will need enormous will power as the mixture is delicious and you may find yourself eating it all there and then. This will make you feel rather ill (trust me).</p>

<p>Finally, add the oats a little bit at a time. It is very important to take your time over this. The mixture gets really thick and heavy, which may be too much for your puny cyclist arms. If you can find a way to stir it with your super-mega strong cyclist legs please tell me in the comments. If not, just ask your wife/mother/mother-in-law/child to help.</p>

<p>Once all that is nicly mixed together transfer it to a tin lined with baking paper (25cm x 15cm should be a good size). Make sure it is firmly pressed down with a metal fork. If not the bar will come apart in your pocket (messy).</p>

<p>Put in the oven for about 15 minutes. When it is nicely golden, take it out and leave it to cool before cutting it up. I find this makes 25-30 small bars (~23-50g each), but your mileage may vary.</p>

<h1>Nutritional Information</h1>

<p>Of course, this being a geeky blog I had to do some maths and comparisons. Note that this is all calculated from the information on the packets and searching on the internet. I am an engineer, not a nutritionist so do not take this as gospel.</p>

<table>
<thead>
<tr>
<th> Bar </th>
<th> weight (g) </th>
<th> Energy (kcal) </th>
<th> Protein (g) </th>
<th> Fat (g) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Mine </td>
<td> ~25-30 </td>
<td> 134          </td>
<td> 1.2         </td>
<td> 6.1</td>
</tr>
<tr>
<td> <a href="http://www.scienceinsport.com/sis-products/sis-rego-range/sis-rego-protein/sis-rego-protein-bar-choc-peanut-55g/">SiS Rego</a> </td>
<td> 55 </td>
<td> 223 </td>
<td> 20 </td>
<td> 6.4 </td>
</tr>
<tr>
<td> <a href="http://highfive.co.uk/product/energy/energybar">High5 Energy Bar</a> </td>
<td> 60 </td>
<td> 194 </td>
<td> 3 </td>
<td> 2 </td>
</tr>
</tbody>
</table>


<p>Mine do not do too badly. Not that both those commercial options have more everything, but they are also much bigger. Two of my bars would beat both of them hands down in all 3 of those measures. It should also be noted that all the fat in these come from the oil and the oats, which is &#8220;healthy fat&#8221; according to High 5.</p>

<p>Like I said, I am an engineer, not a nutritionist. Do not take this as nutritional advise, rather as me sharing something I find works for me. Feel free to use this, but please share your modifications. In fact you are legally obliged to because it is under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a> :-).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VMware CLI on Ubuntu Saucy Salamander]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/04/09/vmware-cli-on-ubuntu-saucy-salamander/"/>
    <updated>2014-04-09T10:51:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/04/09/vmware-cli-on-ubuntu-saucy-salamander</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://www.datanalyzers.com/VMware-Data-Recovery.jpg">The current project (as of this week) has me moving away from Openstack for a while. For the next couple of months I will be immersing myself in monitor, metrics and logging. Naturally, this being a shiney new environment, this involves a significant amount of VMware time.</p>

<!-- more -->


<p>I have inherited an Icinga install running on Ubuntu Server, so I will be needing to run CLI commands to create checks. Simply runnning the installer does not work, as the vmware-cli package is a mixture of 32 and 64 bit commands.</p>

<p>First you need to download the CLI from VMware. How to do that is an exercise for the reader, as I cannot be bothered to find the link (hint: it is not hard). Then you need to install a bunch of packages:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt-get install cpanminus libdata-dump-perl libsoap-lite-perl libclass-methodmaker-perl  libxml-libxml-simple-perl libssl-dev libarchive-zip-perl libuuid-perl lib32z1 lib32ncurses5 lib32bz2-1.0</span></code></pre></td></tr></table></div></figure>


<p>This includes a bunch of Perl modules for munching through XML, plus some 32-bit libraries so that all the tools can work.</p>

<p>Finally, you can extract the tarball and install the CLI:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar xvf VMware-vSphere-CLI-5.5.0-1549297.x86_64.tar.gz
</span><span class='line'>cd vmware-vsphere-cli-distrib/
</span><span class='line'>sudo ./vmware-install.pl</span></code></pre></td></tr></table></div></figure>


<p>I have not tested it, but this will probably be the same process for Debian (at least Wheezy and Sid).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openstack Neutron Performance problems]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/03/31/openstack-neutron-performance-problems/"/>
    <updated>2014-03-31T20:08:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/03/31/openstack-neutron-performance-problems</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/fSMzOUE.jpg">For the last few weeks I have been consulting on a private cloud project for a local company. Unsurprisingly this has been based around the typical Openstack setup.</p>

<ul>
<li>Nova - KVM</li>
<li>Neutron - Openvswitch</li>
<li>Cinder - LVM</li>
<li>Glance - local files</li>
</ul>


<!-- more -->


<p>My architecture is nothing out of the ordinary. A pair of hosts each with 2 networks that look something like this:</p>

<p><img src="https://docs.google.com/drawings/d/11le0qu389WptC78_08Bh92qUCLiCBXiZOhDiESSCnxo/pub?w=960&h=720"></p>

<p>All this is configured using Red Hat RDO. I had done all this under both Grizzly and, using RDO, it was 30 minutes to set up.</p>

<p>Given how common and simple the setup, imagine my surprise when it did not work. What do I mean did not work? From the outset I was worried about Neutron. While I am fairly up to date with SDN in theory, I am fairly green in practise. Fortunately, while RDO does not automate it&#8217;s configuration, there is at least an <a href="http://openstack.redhat.com/Neutron_with_existing_external_network">accurate document</a> in how to configure it.</p>

<p>Now, if I was just using small images that would probably be fine, however this project required Windows images. As a result some problems quickly surfaced. Each time I deployed a new Windows image, everything would lock up:</p>

<ul>
<li>no network access to VM&#8217;s</li>
<li>Openvswitch going mad (800-1000% CPU)</li>
<li>SSH access via eth0 completely dead</li>
</ul>


<p>It has to be said that I initially barked up the wrong tree, pointing the finger at disk access (usually the problem with shared systems). However it turned out I was wrong.</p>

<p>A brief Serverfault/Twitter with @martenhauville brought up a few suggestions, one of which caught my eye:</p>

<blockquote><p>there are known Neutron configuration challenges to overcome with GRE and MTU settings</p><footer><strong>@martenhauville</strong> <cite><a href='https://ask.openstack.org/en/question/25947/openstack-neutron-stability-problems-with-openvswitch/'>ask.openstack.org/en/question/&hellip;</a></cite></footer></blockquote>


<p>This is where my problem lay: the external switch had an MTU of 1500, Openvswitch also. Finally, <code>ip link</code> in a VM would give you</p>

<pre><code>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master br-ex state UP mode DEFAULT qlen 1000
</code></pre>

<p>Everything matches, however I was using GRE tunnels, which add a header to each frame. This was pushing them over 1500 on entry to <code>br-tun</code> causing massive network fragmentation, which basically destroyed Openvswitch every time I performed a large transfer. It showed up when deploying an image, because that is hitting the Glance API over http.</p>

<p>Once armed with this knowledge, the fix is trivial. Add the following to <code>/etc/neutron/dhcp_agent.ini</code>:</p>

<pre><code>dnsmasq_config_file=/etc/neutron/dnsmasq-neutron.conf
</code></pre>

<p>Now create the file <code>/etc/neutron/dnsmasq-neutron.conf</code> which contains the following:</p>

<pre><code>dhcp-option-force=26,1454
</code></pre>

<p>Now you can restart the DHCP agent and all will be well:</p>

<pre><code>service neutron-dhcp-agent restart
</code></pre>

<p>I&#8217;ve gone on a bit in this post, as I feel the background is important. By far the hardest part was diagnosing the problem, without knowing what my background was it would be much harder to narrow down your problem to being the same as mine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logstash on CentOS 6]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/03/21/logstash-on-centos-6/"/>
    <updated>2014-03-21T20:57:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/03/21/logstash-on-centos-6</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://logstash.net/images/logstash.png" width="200"> It&#8217;s been a while since I last posted anything, but it is time to. I&#8217;ve been playing around a lot with various tools for gathering information about my environment recently. One of the most important tools for storing that information is decent logging. Syslog is proven and solid, but a little creaky. For storing everything it is fine, but getting anything out is not so great.</p>

<!-- more -->


<p>Logstash is an awesome tool written by <a href="https://twitter.com/jordansissel">Jordan Sissel</a> that is used to &#8220;collect logs, parse them, and store them for later use (like, for searching)&#8221;. It has an excellent howto, but I have one problem with it: the use of a tar file rather than packages. This easily worked around though, as Elasticsearch have it in their Yum repository.</p>

<p>First up, define that repository in the file <code>/etc/yum.repos.d/logstash.repo</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[logstash-1.4]
</span><span class='line'>name=logstash repository for 1.4.x packages
</span><span class='line'>baseurl=http://packages.elasticsearch.org/logstash/1.4/centos
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=http://packages.elasticsearch.org/GPG-KEY-elasticsearch
</span><span class='line'>enabled=1
</span><span class='line'>
</span><span class='line'>[elasticsearch-1.0]
</span><span class='line'>name=Elasticsearch repository for 1.0.x packages
</span><span class='line'>baseurl=http://packages.elasticsearch.org/elasticsearch/1.0/centos
</span><span class='line'>gpgcheck=1
</span><span class='line'>gpgkey=http://packages.elasticsearch.org/GPG-KEY-elasticsearch
</span><span class='line'>enabled=1</span></code></pre></td></tr></table></div></figure>


<p>The rpm does not create its user and group, nor does it create the PID directory for Kibana. Create those then install Łogstash:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir /var/run/logstash-web
</span><span class='line'>yum -y install logstash elasticsearch logstash-contrib.noarch mcollective-logstash-audit.noarch
</span><span class='line'>chkconfig --add elasticsearch
</span><span class='line'>chkconfig elasticsearch on
</span><span class='line'>service elasticsearch start</span></code></pre></td></tr></table></div></figure>


<p>For the installation that is it. When you reboot the services will start and you are good to go. Before rebooting though it is worth playing around a little. So lets blatantly rip off the <a href="http://logstash.net/docs/1.4.0/tutorials/getting-started-with-logstash">Quickstart</a>. Run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo -u logstash /opt/logstash/bin/logstash -e 'input { stdin { } } output { stdout { codec =&gt; rubydebug } }'</span></code></pre></td></tr></table></div></figure>


<p>Logstash takes a while to get going as it needs to fire up the JRE (hint: run <code>htop</code> in another terminal to see when the Java process calms down). When it is happy type (in the same console you started it in) <code>hello</code>. You should see something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hello
</span><span class='line'>{
</span><span class='line'>       "message" =&gt; "hello",
</span><span class='line'>      "@version" =&gt; "1",
</span><span class='line'>    "@timestamp" =&gt; "2014-03-21T20:56:58.439Z",
</span><span class='line'>          "host" =&gt; "monitor.chriscowley.lan"
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<p>That is not very interesting unfortunately. It just takes STDIN, the logs it to STDOUT in a funky format. This all gets more interesting when you start storing your logs somewhere. A good choice is (funnily enough) Elasticsearch. This time run Logstash with this as the output:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo -u logstash /opt/logstash/bin/logstash -e 'input { stdin { } } output { elasticsearch { host =&gt; localhost } }'</span></code></pre></td></tr></table></div></figure>


<p>Now if you type something in that same console (we&#8217;re still taking the input from STDIN) the output will be written to Elasticsearch.</p>

<p>To test that run <code>curl 'http://localhost:9200/_search?pretty'</code> in another console and you should see something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "took" : 11,
</span><span class='line'>  "timed_out" : false,
</span><span class='line'>  "_shards" : {
</span><span class='line'>    "total" : 5,
</span><span class='line'>    "successful" : 5,
</span><span class='line'>    "failed" : 0
</span><span class='line'>  },
</span><span class='line'>  "hits" : {
</span><span class='line'>      "_index" : "logstash-2014.03.21",
</span><span class='line'>      "_type" : "logs",
</span><span class='line'>      "_id" : "aRFzhx-4Ta-jy_PC50U7Lg",
</span><span class='line'>      "_score" : 1.0, "_source" : {"message":"you know, for logs","@version":"1","@timestamp":"2014-03-21T21:01:17.766Z","host":"monitor.chriscowley.lan"}
</span><span class='line'>    }, {
</span><span class='line'>      "_index" : "logstash-2014.03.21",
</span><span class='line'>      "_type" : "logs",
</span><span class='line'>      "_id" : "VP8WcqOYRuCbpYgGA5S1oA",
</span><span class='line'>      "_score" : 1.0, "_source" : {"message":"another one for the logs","@version":"1","@timestamp":"2014-03-21T21:03:42.480Z","host":"monitor.chriscowley.lan"}
</span><span class='line'>    } ]
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Now that does not persist when you kill Logstash. To do that create a file in <code>/etc/logstash/conf.d/</code> that contains this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>input {
</span><span class='line'>  file {
</span><span class='line'>    path           =&gt; "/var/log/messages"
</span><span class='line'>    start_position =&gt; beginning
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>filter {
</span><span class='line'>  if [type] == "syslog" {
</span><span class='line'>    grok {
</span><span class='line'>      match =&gt; { "message" =&gt; "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
</span><span class='line'>      add_field =&gt; [ "received_at", "%{@timestamp}" ]
</span><span class='line'>      add_field =&gt; [ "received_from", "%{host}" ]
</span><span class='line'>    }
</span><span class='line'>    syslog_pri { }
</span><span class='line'>    date {
</span><span class='line'>      match =&gt; [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>output {
</span><span class='line'>  elasticsearch {
</span><span class='line'>    host =&gt; localhost
</span><span class='line'>  }
</span><span class='line'>  stdout { codec =&gt; rubydebug }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>That gives you a simple setup for storing everything in that systems&#8217; syslog. The logical next step from there is to enable that host a central syslogger. This well documented elsewhere, but simplistically you need to add the following to <code>/etc/rsyslog.conf</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Provides UDP syslog reception
</span><span class='line'>$ModLoad imudp
</span><span class='line'>$UDPServerRun 514
</span><span class='line'>
</span><span class='line'># Provides TCP syslog reception
</span><span class='line'>$ModLoad imtcp
</span><span class='line'>$InputTCPServerRun 514</span></code></pre></td></tr></table></div></figure>


<p>There is a single final step due to the fact that /var/log/messages is only readable by <em>root</em>. Normally this is a big faux pas, but I am putting my trust in Jordan Sissel not to have sold his soul to the NSA. To read this (and connect to ports below 1024) Logstash needs to run as <em>root</em>. Edit <code>/etc/sysconfig/logstash</code> and change the line:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LS_USER=logstash</span></code></pre></td></tr></table></div></figure>


<p>to read:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LS_USER=root</span></code></pre></td></tr></table></div></figure>


<p>Now you can start Logstash and it will pull in <code>/var/log/messages</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service logstash start</span></code></pre></td></tr></table></div></figure>


<p>There are loads of configuration options for Logstash, so have a look in the <a href="http://logstash.net/docs/1.4.0/">main documentation</a> and the <a href="http://cookbook.logstash.net/">Cookbook</a> for more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NFS with Puppet and an ENC]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc/"/>
    <updated>2014-01-24T20:06:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/24/nfs-with-puppet-and-an-enc</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://puppetlabs.com/sites/default/files/PL_logo_horizontal_RGB_0.svg" width="200" height="200">Ages ago (it seems) I posted a <a href="http://www.chriscowley.me.uk/blog/2013/04/11/using-hiera-with-puppet/">howto</a> on configure NFS using Puppet and Hiera. I have been using this happily for several months and adding a new share was is as simple as adding a line to a YAML file. I was never completely happy with it though, especially after I decided to deploy <a href="http://www.theforeman.org">The Foreman</a> in my lab.</p>

<!-- more -->


<p>The reason I was never satisfied is because The Foreman makes a really good ENC. I wanted to use this, so I have modified my module to use an ENC rather than Hiera directly.</p>

<p>OK, first I we need to get the module into a position where it uses parameterized classes. This is actually quite simple.</p>

<p>My original manifest is <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/b5d5fe6eba75379fad37255ceddb55208cbe7208/manifests/server.pp">here</a>. The key item is the <em>$exports</em> variable, which is hiera data. All I did was create a class parameter called <em>exports</em> and removed the variable within the class. You can see the new code <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/server.pp">here</a>. I have also moved the <code>list_exports</code> function out into a <a href="http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs/blob/ab9627cf920f3a87986aa7379168572ca3a55f7e/manifests/list_exports.pp">seperate file</a>. Apparently this makes it more readable, although I am not convinced in this instance.</p>

<p>I also took the chance to update my module a bit so that it was not hard-coded to my own lab network. To that end, it will automatically pull out the IP address and netmask of eth0. You can edit this easily enough using your ENC.</p>

<figure class='code'><figcaption><span>manifests/server.pp  </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='puppet'><span class='line'>  <span class="kd">class</span> <span class="nc">nfs::server</span> <span class="p">(</span>
</span><span class='line'>    <span class="nv">$exports</span> <span class="p">=</span> <span class="p">[</span> <span class="s1">&#39;/srv/share&#39;</span><span class="p">],</span>
</span><span class='line'>    <span class="nv">$networkallowed</span> <span class="p">=</span> <span class="nv">$::network_eth0</span><span class="p">,</span>
</span><span class='line'>    <span class="nv">$netmaskallowed</span> <span class="p">=</span> <span class="nv">$::netmask_eth0</span><span class="p">,</span>
</span><span class='line'>  <span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="err">//</span> <span class="err">Code</span> <span class="err">here</span>
</span><span class='line'>  }
</span></code></pre></td></tr></table></div></figure>


<p>Next we need a simple ENC to supply the data. An ENC is actually just any script that returns YAML. It has a single parameter, which is the FQDN of the node. I use this:</p>

<figure class='code'><figcaption><span>/usr/local/bin/simple-enc.sh </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'><span class="nv">DATADIR</span><span class="o">=</span><span class="s2">&quot;/var/local/enc&quot;</span>
</span><span class='line'><span class="nv">NODE</span><span class="o">=</span><span class="nv">$1</span>
</span><span class='line'>
</span><span class='line'>cat <span class="s2">&quot;${DATADIR}/${NODE}.yaml&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next you need a YAML file that looks like:</p>

<figure class='code'><figcaption><span>/var/local/enc/nfs.example.lan.yaml </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">---</span>
</span><span class='line'><span class="l-Scalar-Plain">environment</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">production</span>
</span><span class='line'><span class="l-Scalar-Plain">classes</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">nfs::server</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">exports</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/srv/share1</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">/srv/share3</span>
</span><span class='line'>    <span class="l-Scalar-Plain">networkallowed</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">192.168.0.0</span>
</span><span class='line'>    <span class="l-Scalar-Plain">netmaskallowed</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">255.255.255.0</span>
</span><span class='line'><span class="l-Scalar-Plain">parameters</span><span class="p-Indicator">:</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, you need to enable this on your Puppet master. Add this to <code>/etc/puppet/puppet.conf</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[master]
</span><span class='line'>    node_terminus = exec
</span><span class='line'>    external_nodes = /usr/local/bin/simple-enc.sh</span></code></pre></td></tr></table></div></figure>


<p>Now whenever a node with the FQDN nfs.example.lan syncs with the master it runs <code>/usr/local/bin/simple-enc.sh nfs.examle.lan.yaml</code>. This returns the contents of the YAML file above. The layout of it is pretty logical, but I suggest reading Puppetlabs <a href="http://docs.puppetlabs.com/guides/external_nodes.html">docs</a>.</p>

<p>How is this better than the previous Hiera setup? First I can now use my module with The Foreman which answers my immediate need. Second I can now submit this module to the Forge with a warm fuzzy feeling inside as I am a good citizen. not only does it work with Puppet 3, but also really old versions of Puppet that do not support an ENC or Hiera. It can do this because the user can still edit the class parameters directly, or set the in <code>site.pp</code> (<strong>DON&#8217;T DO THAT</strong>).</p>

<p>You can install the module on your own Puppet master with:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone http://gitlab.chriscowley.me.uk/puppet/chriscowley-nfs.git \
</span><span class='line'>    /etc/puppet/modules/nfs/</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RHEL and CentOS joining forces]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces/"/>
    <updated>2014-01-08T14:34:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2014/01/08/rhel-and-centos-joining-forces</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/3colCNj.png" width="200" height="200">Yesterday saw probably the biggest FLOSS news in recent times. Certainly the biggest news of 2014 so far :-) By some freak of overloaded RSS readers, I missed the announcement, but I did see this:</p>

<blockquote class="twitter-tweet" lang="en"><p>Day 1 at the new job. Important stuff first.. Where do I get my Red Hat ?</p>&mdash; Karanbir Singh (@CentOS) <a href="https://twitter.com/CentOS/statuses/420876286785892353">January 8, 2014</a></blockquote>


<script async src="http://www.chriscowley.me.uk//platform.twitter.com/widgets.js" charset="utf-8"></script>


<!-- more -->


<p>It did not take long to dig up <a href="http://community.redhat.com/centos-faq/?utm_content=buffer6403d&amp;utm_source=buffer&amp;utm_medium=twitter&amp;utm_campaign=Buffer">this</a> and <a href="http://lists.centos.org/pipermail/centos-announce/2014-January/020100.html">this</a>, where Red Hat and CentOS respectively announce that they have joined forces. Some things from the announcement struck me:</p>

<blockquote><p> Some of us now work for Red Hat, but not RHEL</p></blockquote>

<p>That is important! This says to me that Red Hat see the value of CentOS as an entity in itself. By not linking the CentOS developers to RHEL in anyway, they are not going to be side-tracking them. Instead, they are simple freeing them up to work more effectively on CentOS.</p>

<blockquote><p>we are now able to work with the Red Hat legal teams</p></blockquote>

<p>QA was always a problem for CentOS, simply because it took place effectively in secret. Now they can just walk down the corridor to talk to the lawyers who would have previously (potentially) sued them, all the potential problems go away.</p>

<h1>The RHEL Ecosystem</h1>

<p><span class='pullquote-right' data-pullquote='In Fedora things can break without people really worrying'>
In the beginning there is <a href="http://fedoraproject.org">Fedora</a>), where the RHEL developers get to play. Here is where they can try new things and make mistakes. In Fedora things can break without people really worrying (especially in Rawhide). The exception to this is my wife as we run it on the family PC and she gets quite frustrated with its foibles. However, she knew she was marrying a geek from the outset, so I will not accept any blame for this.
</span>}</p>

<p>Periodically, the the Fedora developers will pull everything together and create a release that has the potential to be transformed into RHEL. Here they pull together all the things that have be learnt over the last few releases. I consider this an Alpha release of RHEL. At this point, behind the scenes, the RHEL developers will take those packages and start work on the next release of RHEL.</p>

<p><span class='pullquote-right' data-pullquote='Red Hat as a company are built on Open Source'>
On release of RHEL, Red Hat make the source code available, as required by the terms of the GPL (and other relevant licenses).The thing is, Red Hat as a company are built on Open Source principles, they firmly believe in them and, best of all, they practise what the preach. They would still be within the letter of the law if the just dumped a bunch of apparently random scripts on a web server. Instead, they publish the SRPM packages used to build RHEL.
</span></p>

<p>CentOS then take these sources and get to work. By definition they are always beind RHEL. As many know this got pretty bad at one point:</p>

<p><img src="http://www.standalone-sysadmin.com/~matt/centos-delays.jpg" title="center" ></p>

<p>(Thanks to Matt Simmons, aka <a href="http://www.standalone-sysadmin.com">Standalone Sysadmin</a>, from whom I blatantly stole that graph, I&#8217;ll ask permission later)</p>

<p>Since then, things have got better, with new point releases coming hot on the heels of RHEL. Certainly preparations for EL7 seemed to be going on nicely even before this announcement.</p>

<h1>how does this now affect the two projects</h1>

<p>Both CentOS and Red Hat have a lot to gain from this alliance. <img class="right" src="http://i.imgur.com/qbKvXko.jpg" width="350" height="350">I am sure that there are few people in the wider community who will be upset, but I think that it is a good thing. The reality is that CentOS and RHEL have never been enemies. The people that are using CentOS are just simply never going to pay Red Hat for support they do not need.</p>

<p>When I started at Snell (then Snell &amp; Wilcox), the official line was to use RHEL for all our Linux servers. They had everything paid up for a couple of years at the time. By the time renewal came around the global financial crisis had hit, we had used the support two or three times and each time I had solved the problem before Red Hat answered the ticket. So, we decided to switch to CentOS (which was trivial).</p>

<p>At the other end of the scale you have the web-scale people. For them, paying Red Hat for support is both unnecessary (they have the right people on staff) and prohibitively expensive. When you have tens of thousands of nodes you cannot use a licensing model that support each one.</p>

<p>In the cloud model you also have a problem, in that you are effectively renting an OS. Microsoft and Red Hat you have an administrative overhead of ensuring you have the right licenses available. In my experience Red Hat make it a lot easier, but it is an overhead none the less.</p>

<p>All three of these will get a huge benefit. Now that the CentOS developers are on staff at Red Hat they have direct access to the source code. There should no longer be any need to wait for RHEL to drop before they start building. Red Hat will be supplying infrastructure and community support, which will also be a massive bonus.</p>

<p>So what do Red Hat gain? In terms of new customers, they may get some of that first group. These are the people that may well do their testing with CentOS, but may now choose to go production with RHEL. I certainly would be more willing to now that XFS is not in a separate (expensive) RAN channel. I do not see the cloud or web-scale people changing to a paid support model. It will remain prohibitively expensive for them.</p>

<p>I think they biggest thing that Red Hat will gain is that get to give Oracle a good kicking. Oracle basically do the same thing as CentOS, but they stick a thumping great big support charge on it. To be honest I have never really worked out why anyone would use it. Yes they are cheaper than Red Hat, but not by much. A couple of years ago Red Hat took steps to <a href="http://www.theregister.co.uk/2011/03/04/red_hat_twarts_oracle_and_novell_with_change_to_source_code_packaging/">make life harder</a>. That had an unfortunate knock-on effect on CentOS, causing the huge delay in CentOS 6. Now CentOS should not have that problem as they are closer to source.</p>

<h1>TL;DR</h1>

<p>CentOS and RHEL joining forces is in my opinion a really good thing, with both parties getting significant benefits. Granted they are bit less tangible for Red Hat, but that does not make them any less significant.</p>

<p>Personally I am really excited to see what it is in store - especially from CentOS. I even have a couple of SIG ideas too.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integrating RHEL with Active Directory]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/12/16/integrating-rhel-with-active-directory/"/>
    <updated>2013-12-16T09:52:00+01:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/12/16/integrating-rhel-with-active-directory</id>
    <content type="html"><![CDATA[<p>I had a request on Reddit to share a document I wrote about connect Red Hat Enterprise Linux with Active Directory. The original document I wrote is confidential, but I said I would write it up.</p>

<p>This works for both Server 2008(R2) and 2012. If I recall correctly it will also work with 2003, but may need to minor terminology changes on the Windows side. From the Linux side, it should be fine with RHEL 6 and similar (CentOS and Scientific Linux). It should also apply to Fedora, but your mileage may vary.</p>

<!-- more -->


<p>So without further ado, let&#8217;s dive in. To do this you need to know what is actually happening under the surface when you authenticate to AD from a client. The basic idea looks something like this:</p>

<p><img class="center" src="https://docs.google.com/drawings/d/1tjaacfXrTJtOZCREonoXzdHfgZQHssQ2zkDzFpLGeX0/pub?w=960&h=720"></p>

<p>Integration with AD requires the installation of a few services in Red Hat, along with some minor modifications on the Windows Domain Controllers. On the Linux side, everything revolves around the System Security Services Daemon (SSSD). All communication between the PAM and the various possible back-ends is brokered through this daemon. This is only one solution, there are several. The others involve Winbind (which I have found problematic), or LDAP/Kerberos directly (no offline authentication, more difficult to set up). Note that this does not give you any file sharing, but  can easily be extended to do so using Samba.</p>

<p>PAM communicates with SSSD, which in turn talks to Active Directory via LDAP and Kerberos. Identification is performed via LDAP, with the user is authenticated using Kerberos. These different components have some prerequisites on Windows.</p>

<ul>
<li>DNS must be working fully - both forward and reverse lookups should be functional. If the Kerberos server (Windows Domain Controller) cannot identify the client via DNS, Kerberos will fail.</li>
<li>Accurate time is essential – if the two systems have too larger difference in time (about 5 minutes), Kerberos will fail.</li>
<li>The Active Directory needs to be extended to include the relevant information for *NIX systems (home directory, shell, UUID/GUID primarily).

<ul>
<li>They are actually there, but empty and uneditable. The necessary GUI fields are part of “Identity Management for UNIX”</li>
</ul>
</li>
<li>It must be possible for the Linux client to perform an LDAP search. This could be either via an anonymous bind or authenticated.

<ul>
<li>Anonymous is obviously not recommended.</li>
<li>Simple binds (username/password) do work but are not recommended. Although I am not one to practise what I preach (see below).</li>
<li>The best option is SASL/GSSAPI, using a keytab generated by Samba. This does not require Admin privileges on Windows, only permissions to join computers to the domain.</li>
</ul>
</li>
</ul>


<p>For both DNS and NTP I&#8217;m assuming that you are using the services provided by Active Directory. It is possible to break those out to other boxes, but it beyond my Windows Admin ability/desire to do so.</p>

<h1>Preparing Active Directory</h1>

<p>In Server Manager, add the Role Service &#8220;Identity Management for UNIX&#8221;. This is under the Role &#8220;Active Directory Domain Services&#8221; (took me a while to find that). When it asks, use your AD domain name as the NIS name. For example, with a AD domain of <em>chriscowley.lab</em>, use <em>chriscowley</em>.</p>

<p>Once that is installed, create a pair of groups. For the sake of argument, lets call them <em>LinuxAdmin</em> and <em>LinuxUser</em>. The intended roles of these 2 groups is left as an exercise for the reader. When you create these groups, you will see a new tab in the properties window for both groups and users: &#8220;UNIX Attributes&#8221;.</p>

<p>Now go ahead and create a user (or edit an existing one). Go into the UNIX tab and set the configure the user for UNIX access: <img class="right" src="http://i.imgur.com/Ox9kuAy.png"></p>

<ul>
<li>Select the NIS domain you created earlier</li>
<li>Set an approprate UUID (default should be fine)</li>
<li>Set the login shell as <code>/bin/bash</code>, <code>/bin/sh</code> should be fine most of the time, but I have seen a few odd things happen (details escape me)</li>
<li>Set the home directory. I seperate them out from local users to something like <code>/home/&lt;DOMAIN&gt;/&lt;username&gt;</code></li>
</ul>


<p>Open up one of your groups (let&#8217;s start with LinuxAdmin) and add the user to that group. Note you have to do it 2 places (don&#8217;t blame me, I am just the messenger). Both in the standard Groups tab, but also in the UNIX attributes tab.</p>

<p>That should be everything on the Windows side.</p>

<h1>Configure RHEL as a client</h1>

<p>Most of the heavy lifting is done by the <em>System Security Service Daemon</em> (SSSD).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install sssd sssd-client krb5-workstation samba openldap-clients policycoreutils-python</span></code></pre></td></tr></table></div></figure>


<p>This should also pull in all the dependencies.</p>

<h2>Configure Kerberos</h2>

<p>I&#8217;ve already said, this but I will repeat myself as getting it wrong will cause many lost hours.</p>

<ul>
<li>DNS must be working for both forward and reverse lookups</li>
<li>Time must be in sync accross all the clients</li>
</ul>


<p>Make sure that /etc/resolv.conf contains your domain controllers.</p>

<p><strong>Gotcha</strong>: In RHEL/Fedora the DNS setting are defined in /etc/sysconfig/network-settings/ifcfg-eth0 (or whichever NIC comes first) by Anaconda. This will over-write /etc/resolv.conf on reboot. For no good reason other than stubbornness I tend to remove these entries and define resolv.conf myself (or via configuration management). Alternatively put DNS1 and DNS2 entries in the network configuration files.</p>

<p>In <code>/etc/krb5.conf</code> change you servers to point at your Domain Controllers.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[logging]
</span><span class='line'> default = FILE:/var/log/krb5libs.log
</span><span class='line'>
</span><span class='line'>[libdefaults]
</span><span class='line'> default_realm = AD.EXAMPLE.COM
</span><span class='line'> dns_lookup_realm = true
</span><span class='line'> dns_lookup_kdc = true
</span><span class='line'> ticket_lifetime = 24h
</span><span class='line'> renew_lifetime = 7d
</span><span class='line'> rdns = false
</span><span class='line'> forwardable = yes
</span><span class='line'>
</span><span class='line'>[realms]
</span><span class='line'> AD.EXAMPLE.COM = {
</span><span class='line'>  # Define the server only if DNS lookups are not working
</span><span class='line'>#  kdc = server.ad.example.com
</span><span class='line'>#  admin_server = server.ad.example.com
</span><span class='line'> }
</span><span class='line'>
</span><span class='line'>[domain_realm]
</span><span class='line'> .ad.example.com = AD.EXAMPLE.COM
</span><span class='line'> ad.example.com = AD.EXAMPLE.COM</span></code></pre></td></tr></table></div></figure>


<p>You should now be able to run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kinit aduser@AD.EXAMPLE.COM</span></code></pre></td></tr></table></div></figure>


<p>That should obtain a kerberos ticket (check with <code>klist</code>) and you can move on. If it does not work fix it now - Kerberos is horrible to debug later.</p>

<h2>Enable LDAP Searches</h2>

<p>The best way to bind to AD is using SASL/GSSAPI as no passwords are needed.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kinit Administrator@AD.EXAMPLE.COM
</span><span class='line'>net ads join createupn=host/client.ad.example.com@AD.EXAMPLE.COM –k
</span><span class='line'>net ads keytab create 
</span><span class='line'>net ads keytab add host/client.ad.example.com@AD.EXAMPLE.COM</span></code></pre></td></tr></table></div></figure>


<p>You should now be able to get information about yourself from AD using ldapsearch:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ldapsearch -H ldap://server.ad.example.com/ -Y GSSAPI -N -b "dc=ad,dc=example,dc=com" "(&(objectClass=user)(sAMAccountName=aduser))"</span></code></pre></td></tr></table></div></figure>


<h2>Configure SSSD</h2>

<p>Everything in SSSD revolves around a single config file (/etc/sssd/ssd.conf).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[sssd]
</span><span class='line'> config_file_version = 2
</span><span class='line'> domains = ad.example.com
</span><span class='line'> services = nss, pam
</span><span class='line'> debug_level = 0
</span><span class='line'>
</span><span class='line'>[nss]
</span><span class='line'>
</span><span class='line'>[pam]
</span><span class='line'>
</span><span class='line'>[domain/ad.example.com]
</span><span class='line'> id_provider = ldap
</span><span class='line'> auth_provider = krb5 
</span><span class='line'> chpass_provider = krb5
</span><span class='line'> access_provider = ldap
</span><span class='line'>
</span><span class='line'> # To use Kerberos, un comment the next line
</span><span class='line'> #ldap_sasl_mech = GSSAPI
</span><span class='line'>
</span><span class='line'> # The following 3 lines bind to AD. Comment them out to use Kerberos
</span><span class='line'> ldap_default_bind_dn = CN=svc_unix,OU=useraccounts,DC=ad,DC=example,DC=com
</span><span class='line'> ldap_default_authtok_type = password
</span><span class='line'> ldap_default_authtok = Welcome_2014
</span><span class='line'>
</span><span class='line'> ldap_schema = rfc2307bis
</span><span class='line'>
</span><span class='line'> ldap_user_search_base = ,dc=ad,dc=example,dc=com
</span><span class='line'> ldap_user_object_class = user
</span><span class='line'> 
</span><span class='line'> ldap_user_home_directory = unixHomeDirectory
</span><span class='line'> ldap_user_principal = userPrincipalName
</span><span class='line'>
</span><span class='line'> ldap_group_search_base = ou=groups,dc=ad,dc=example,dc=com
</span><span class='line'> ldap_group_object_class = group
</span><span class='line'> 
</span><span class='line'> ldap_access_order = expire
</span><span class='line'> ldap_account_expire_policy = ad
</span><span class='line'> ldap_force_upper_case_realm = true
</span><span class='line'>
</span><span class='line'> krb5_realm = AD.EXAMPLE.COM</span></code></pre></td></tr></table></div></figure>


<p>There is something wrong here. Note the lines:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> # To use Kerberos, un comment the next line
</span><span class='line'> #ldap_sasl_mech = GSSAPI
</span><span class='line'> 
</span><span class='line'> # The following 3 lines bind to AD. Comment them out to use Kerberos
</span><span class='line'> ldap_default_bind_dn = CN=svc_unix,OU=useraccounts,DC=ad,DC=example,DC=com
</span><span class='line'> ldap_default_authtok_type = password
</span><span class='line'> ldap_default_authtok = Welcome_2014</span></code></pre></td></tr></table></div></figure>


<p>Instead of doing the SASL/GSSAPI bind I would prefer to do I have chickened out and done a simple bind. Why? Because I am weak&#8230; :-(</p>

<p>Try with kerberos first, if it works then awesome, if not then create a service account in AD that can do nothing other than perform a search and use that to perform the bind. Make sure its path matches that of the <em>ldap_default_bind_dn</em> path, also make sure the password is more complex than &#8220;Welcome_2014&#8221;.</p>

<p>For now this does nothing, we need to tell PAM to use it. The easiest way to enable this on RHEL is to use the authconfig command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>authconfig --enablesssd --enablesssdauth --enablemkhomedir –update</span></code></pre></td></tr></table></div></figure>


<p>This will update <code>/etc/nsswitch.conf</code> and various files in <code>/etc/pam.d</code> to tell the system to authenticate against SSSD. SSSD will in turn talk to Active Directory, using LDAP for Identification and Kerberos for authentication.
Finally you can enable your LinuxAdmin’s to use sudo. Run the command visudo and add the line:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>%LinuxAdmin ALL=(ALL)       ALL
</span><span class='line'># note the % sign, the defines it as a group not a user</span></code></pre></td></tr></table></div></figure>


<p>Now your admin’s can run commands as root by prefacing them with sudo. For an encore, I would suggest disabling root login via SSH. Log in as your AD user (leave your root session open, just in case) and run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo sed -i 's/PermitRootLogin no/PermitRootLogin yes/' /etc/ssh/sshd_config
</span><span class='line'>sudo service sshd reload</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The End of Centralised Storage]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/09/12/the-end-of-centralised-storage/"/>
    <updated>2013-09-12T20:20:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/09/12/the-end-of-centralised-storage</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://www.chriscowley.me.uk/images/NetappClustering.jpg">That is a pretty drastic title, especially given that I spend a significant part of my day job working with EMC storage arrays. The other day I replied to a tweet by <a href="http://blog.scottlowe.org">Scott Lowe</a> :</p>

<blockquote class="twitter-tweet"><p><a href="https://twitter.com/scott_lowe">@scott_lowe</a> with things like Gluster and Ceph what does shared storage actually give apart from complications?</p>&mdash; Chris Cowley (@chriscowleyunix) <a href="https://twitter.com/chriscowleyunix/statuses/377900529760083968">September 11, 2013</a></blockquote>


<script async src="http://www.chriscowley.me.uk//platform.twitter.com/widgets.js" charset="utf-8"></script>


<!-- more -->


<p>Due to time-zone differences between France and the USA I missed out on most of the heated conversation that ensued. From what I could see it quickly got out of hand, with people replying to so many others that they barely had any space to say anything. I am sure it has spawned a load of blog posts, as Twitter is eminently unsuitable for that sort of conversation (at least I have seen one by <a href="http://storagezilla.typepad.com/storagezilla/2013/09/tomorrows-das-yesterday.html">StorageZilla</a>.</p>

<p>The boundary between DAS (Direct Attached Storage) and remote storage (be that a SAN or NAS) is blurring. Traditionally a SAN/NAS array is a proprietary box that gives you bits of disk space that is available to whatever server (or servers) that you want. Conversely, DAS is attached either inside the server or to the back of it. Sharing between multiple servers is possible, but not very slick - no switched fabric, no software configuration, cables have to be physically moved.</p>

<p>Now everything is blurring. In the FLOSS world there is the like of Ceph and GlusterFS, which take your DAS (or whatever) and turn that into a shared pool of storage. You can put this on dedicated boxes, depending on your workload that may well be the best idea. However you are not forced to. To my mind this is a more elegant solution. I have a collection of identical servers, I use some for compute, other for storage, others for both. You can pick and choose, even doing it live.</p>

<p>The thing is, even the array vendors are now using DAS. An EMC VNX is commodity hardware, as is the VMAX (mostly, I believe there is an ASIC used in the encryption engine), Isilion, NetApp, Dell Compellent, HP StoreVirtual (formerly Lefthand). What is the difference in the way they attach their disks? Technically none I suppose, it is just hidden away.</p>

<p>Back to the cloud providers, when you provision a VM there is a process that happens (I am considering Openstack, as that is my area of interest/expertise). You provision an instance and it takes the template you select and copies it to the local storage on that host. Yes you can short-circuit that and use shared storage, but that is unnecessarily complex and introduces a potential failure point. OK, the disk in the host could fail, but then so would the host and it would just go to a new host.</p>

<p>With Openstack, you can use either Ceph or GlusterFS for your block storage (amongst others). When you create block storage for your instance it is created in that pool and replicated. Again, these will in most cases be distributing and replicating local storage. I have known people use SAN arrays as the back-end for Ceph, but that was because they already had them lying around.</p>

<p>There have been various products around for a while to share out your local storage on VMware hosts. VMware&#8217;s own VSA, HP StoreVirtual and now Virtual SAN takes this even deeper, giving tiering and tying directly into the host rather than using a VSA. It certainly seems that DAS is the way forward (or a hybrid approach such as PernixData FVP). This makes a huge amount of sense, especially in the brave new world of SSDs. The latencies involved in spinning rust effective masked those of the storage fabric. Now though SSDs are so fast, that the time it takes for a storage object to transverse the SAN becomes a factor. Getting at least the performance storage layer as physically close to the computer layer as possible is now a serious consideration.</p>

<p>Hadoop, the darling of the Big Data lovers, uses HDFS, which also distributes and replicates your data across local storage. GlusterFS can also be used too. You can use EMC arrays, but I do not hear much about that (other than from EMC themselves). The vast majority of Hadoop users seem to be on local storage/HDFS. On a similar note Lustre, very popular in the HPC world, is also designed around local storage.</p>

<p><span class='pullquote-right' data-pullquote='I just do not see anything really exciting in centralised storage'>
So what am I getting at here? To be honest I am not sure, but I can see a general move away from centralised storage. Even EMC noticed this ages ago - they were talking about running the hypervisor on the VNX/VMAX. At least that is how I remember it anyway, I may well be wrong (if I am, then it is written on the internet now, so it must be true). Red Hat own GlusterFS and are pushing it centre stage for Openstack, Ceph is also an excellent solution and has the weight of Mark Shuttleworth and Canonical behind it. VMware have been pushing Virtual SAN hard and it seems to have got a lot of people really excited. I just do not see anything really exciting in centralised storage, everything interesting is based around DAS.
</span></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Source Virtual SAN thought experiment]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/09/05/open-source-virtual-san-thought-experiment/"/>
    <updated>2013-09-05T21:19:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/09/05/open-source-virtual-san-thought-experiment</id>
    <content type="html"><![CDATA[<p>Okay, I know I am little slow on the uptake here, but I was on holiday at the time. The announcement of <a href="https://www.vmware.com/products/virtual-san/">Virtual SAN</a> at VMWorld the last week got me thinking a bit.</p>

<!-- more -->


<p>Very briefly, Virtual SAN takes locally attached storage on you hypervisors. It then turns it into a distributed object storage system which you can use to store your VMDKs. <a href="http://www.yellow-bricks.com/2013/09/05/how-do-you-know-where-an-object-is-located-with-virtual-san/">Plenty</a> <a href="http://www.computerweekly.com/news/2240166057/VMware-Virtual-SAN-vision-to-disrupt-storage-paradigm">of</a> <a href="http://chucksblog.emc.com/chucks_blog/2013/08/considering-vsan.html">other</a> <a href="http://architecting.it/2013/08/29/reflections-on-vmworld-2013/">people</a> have gone into a lot more detail. Unlike other systems that did a similar job previously this is not a Virtual Appliance, but runs on the hypervisors themselves.</p>

<p>The technology to do this sort of thing using purely Open Source exists. All this has added is a distributed storage layer on each hypervisor. There are plenty of these exist for Linux, with my preference probably being for GlusterFS. Something like this is what I would have in mind:</p>

<p><img class="center" src="http://i.imgur.com/NHYdf78.png"></p>

<p>Ceph is probably the closest to Virtual SAN, as it is fundamentally object-based. Yes there would be CPU and RAM overhead, but that also exists for Virtual SAN too. Something like DRBD/GFS2 is not really suitable here, because it will not scale-out as much. You would not have to have local storage in all your hypervisor nodes (as with Virtual SAN) too.</p>

<p>I honestly do not see any real problems with this.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Home-made Energy Drink]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/08/01/home-made-energy-drink/"/>
    <updated>2013-08-01T11:23:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/08/01/home-made-energy-drink</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://farm8.staticflickr.com/7120/7645659336_357c65c781.jpg" width="400" height="300">This is a post which breaks from the normal subjects of Linux and storage.</p>

<p>Today I am going to share a very simple recipe for what I drink when I am cycling. I have some fairly simple requirements for this.</p>

<!-- more -->


<ol>
<li>It must work (it must rehydrate me effectively)</li>
<li>It must not be a rip off</li>
<li>I want to have a at least a reasonable idea of what is in it.</li>
</ol>


<p>You can spend a small fortune on these drinks. Exercise nutrition is big business, but starting at roughly 1 euro a bottle (3-4 euros a day at this time of year, plus my hay fever medicines) they can get pricey.</p>

<p>In reality you need 3 things:</p>

<ol>
<li>Water, and plenty of it</li>
<li>Sugar to give you back the fuel you burn.</li>
<li>Salt to help you absorb the fluid</li>
</ol>


<p>I use  500ml bottles from my <a href="http://www.laboutiqueducycle.fr/">LBS</a> that I chose for very technical reasons (they gave them to me free).</p>

<p>The important thing to get right is the proportions. Not enough sugar and you will not replace the glucose that you burn, too much and you will struggle to absorb it. Likewise with salt, not enough and you&#8217;re absorption rate will be to slow, too much and it will 1) taste nasty and 2) dehydrate you.</p>

<p>For each 500ml bottle I go for:</p>

<ul>
<li>3 teaspoon sugar (15-20g)</li>
<li>2-3  pinchs of salt</li>
</ul>


<p>That would taste disgusting, so add a touch of fruit squash to taste. I use Grenadine, because the children love it so it always in the fridge, but a sugar-free squash would be fine or a dash for fresh fruit juice. To allow for the extra sugar in the Grenadine, I cut down the added sugar by 1 teaspoon.</p>

<p>Finally, I use unrefined sugar and for the salt I use <a href="http://en.wikipedia.org/wiki/Gu%C3%A9rande#Salt_marshes">Sel de Guérande</a>. That way I know I am using the best quality ingredients, something I am sure the likes of Gatorade do not do.</p>

<p>Final cost is minimal, but it seems to work for me. Everyone is different, so these levels need adjusting for you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Connect to Fedora 19 with FreeNX]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/08/01/connect-to-fedora-19-with-freenx/"/>
    <updated>2013-08-01T10:17:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/08/01/connect-to-fedora-19-with-freenx</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://i.imgur.com/Z8LFhPUl.png" width="400" height="250"> FreeNX is a great remote desktop protocol. I find it more responsive than VNC and it uses less bandwidth. The biggest advantage though (in my eyes) is that it uses SSH to do the authentication. With VNC, each user has to arrange another password to connect to their VNC session.</p>

<!-- more -->


<p>However, FreeNX is still not really working nicely with GNOME 3. If you use KDE you are fine, but I like GNOME and many of the programs are GTK as a result. This means that they look out of place on KDE, which causes my engineer OCD super-sensory powers to go mad.</p>

<p>My workaround is to effectively go back to the tried and tested Gnome 2 environment, nowadays know as MATE.</p>

<p>Get the server installed and configured along with the MATE desktop:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo yum -y groupinstall "MATE desktop"
</span><span class='line'>sudo yum -y install freenx-server
</span><span class='line'>sudo /usr/libexec/nx/nxsetup --install --setup-nomachine-key
</span><span class='line'>sudo chkconfig freenx-server on</span></code></pre></td></tr></table></div></figure>


<p>Now open <code>/etc/nxserver/node.conf</code> and un-comment the line that sets the <code>COMMAND_START_GNOME</code> variable. You need to edit this line to read:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>COMMAND_START_GNOME=mate-session</span></code></pre></td></tr></table></div></figure>


<p>and restart the server with <code>sudo service freenx-server restart</code></p>

<p>Now connect to it using the NX client and chose to use a unix-gnome desktop. Instead of firing up <code>gnome-session</code> (which will fail) it will now run <code>mate-session</code> and you are happy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automated GlusterFS]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/06/23/automated-glusterfs/"/>
    <updated>2013-06-23T22:02:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/06/23/automated-glusterfs</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://www.hastexo.com/system/files/imagecache/sidebar/20120221105324808-f2df3ea3e3aeab8_250_0.png"> As I promised on Twitter, this is how I automate a GlusterFS deployment. I&#8217;m making a few assumptions here:</p>

<!-- more -->


<ul>
<li>I am using CentOS 6, so should work on RHEL 6 and Scientific Linux 6 too. Others may work, but YMMV.

<ul>
<li>As I use XFS, RHEL users will need the <em>Scalable Storage</em> option. Ext4 will work, but XFS is recommended.</li>
</ul>
</li>
<li>That you have a way of automating your base OS installation. My personal preference is to use <a href="https://github.com/puppetlabs/Razor">Razor</a>.</li>
<li>You have a system with at least a complete spare disk dedicated to a GlusterFS brick. That is the best way to run GlusterFS anyway.</li>
<li>You have 2 nodes and want to replicate the data</li>
<li>You have a simple setup with only a single network, because I am being lazy. As a proof-of concept this is fine. Modifying this for second network is quite easy, just change the IP address in you use.</li>
</ul>


<p><img src="https://docs.google.com/drawings/d/1XA7GH3a4BL1uszFXrSsZjysi59Iinh-0RmhqdDbt7QQ/pub?w=673&h=315" title="'simple gluster architecture'" ></p>

<p>The diagram above shows the basic layout of what to start from in terms of hardware. In terms of software, you just need a basic CentOS 6 install and to have Puppet working.</p>

<p>I use a pair of Puppet modules (both in the Forge): <a href="http://forge.puppetlabs.com/thias/glusterfs">thias/glusterfs</a> and <a href="http://forge.puppetlabs.com/puppetlabs/lvm">puppetlabs/lvm</a>. The GlusterFS module CAN do the LVM config, but that strikes me as not the best idea. The UNIX philosophy of &#8220;do one job well&#8221;  holds up for Puppet modules as well. You will also need my <a href="https://github.com/chriscowley/puppet-yumrepos">yumrepos</a> module.</p>

<p>Clone those 3 modules into your modules directory:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd /etc/puppet/
</span><span class='line'>git clone git://github.com/chriscowley/puppet-yumrepos.git modules/yumrepos
</span><span class='line'>puppet module install puppetlabs/lvm --version 0.1.2
</span><span class='line'>puppet module install thias/glusterfs --version 0.0.3</span></code></pre></td></tr></table></div></figure>


<p>I have specified the versions as that is what was the latest at the time of writing. You should be able to take the latest as well, but comment with any differences if any. That gives the core of what you need so you can now move on to you <code>nodes.pp</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class basenode {
</span><span class='line'>  class { 'yumrepos': }
</span><span class='line'>  class { 'yumrepos::epel': }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>class glusternode {
</span><span class='line'>  class { 'basenode': }
</span><span class='line'>  class { 'yumrepos::gluster': }
</span><span class='line'>  
</span><span class='line'>  volume_group { "vg0":
</span><span class='line'>    ensure =&gt; present,
</span><span class='line'>    physical_volumes =&gt; "/dev/sdb",
</span><span class='line'>    require =&gt; Physical_volume["/dev/sdb"]
</span><span class='line'>  }
</span><span class='line'>  physical_volume { "/dev/sdb":
</span><span class='line'>    ensure =&gt; present
</span><span class='line'>  }
</span><span class='line'>  logical_volume { "gv0":
</span><span class='line'>    ensure =&gt; present,
</span><span class='line'>    require =&gt; Volume_group['vg0'],
</span><span class='line'>    volume_group =&gt; "vg0",
</span><span class='line'>    size =&gt; "7G",
</span><span class='line'>  }
</span><span class='line'>  file { [ '/export', '/export/gv0']:
</span><span class='line'>    seltype =&gt; 'usr_t',
</span><span class='line'>    ensure =&gt; directory,
</span><span class='line'>  }
</span><span class='line'>  package { 'xfsprogs': ensure =&gt; installed
</span><span class='line'>  }
</span><span class='line'>  filesystem { "/dev/vg0/gv0":
</span><span class='line'>    ensure =&gt; present,
</span><span class='line'>    fs_type =&gt; "xfs",
</span><span class='line'>    options =&gt; "-i size=512",
</span><span class='line'>    require =&gt; [Package['xfsprogs'], Logical_volume['gv0'] ],
</span><span class='line'>  }
</span><span class='line'>  
</span><span class='line'>  mount { '/export/gv0':
</span><span class='line'>    device =&gt; '/dev/vg0/gv0',
</span><span class='line'>    fstype =&gt; 'xfs',
</span><span class='line'>    options =&gt; 'defaults',
</span><span class='line'>    ensure =&gt; mounted,
</span><span class='line'>    require =&gt; [ Filesystem['/dev/vg0/gv0'], File['/export/gv0'] ],
</span><span class='line'>  }
</span><span class='line'>  class { 'glusterfs::server':
</span><span class='line'>    peers =&gt; $::hostname ? {
</span><span class='line'>      'gluster1' =&gt; '192.168.1.38', # Note these are the IPs of the other nodes
</span><span class='line'>      'gluster2' =&gt; '192.168.1.84',
</span><span class='line'>    },
</span><span class='line'>  }
</span><span class='line'>  glusterfs::volume { 'gv0':
</span><span class='line'>    create_options =&gt; 'replica 2 192.168.1.38:/export/gv0 192.168.1.84:/export/gv0',
</span><span class='line'>    require =&gt; Mount['/export/gv0'],
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>node 'gluster1' {
</span><span class='line'>  include glusternode
</span><span class='line'>  file { '/var/www': ensure =&gt; directory }
</span><span class='line'>  glusterfs::mount { '/var/www':
</span><span class='line'>    device =&gt; $::hostname ? {
</span><span class='line'>      'gluster1' =&gt; '192.168.1.84:/gv0',
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>node 'gluster2' {
</span><span class='line'>  include glusternode
</span><span class='line'>  file { '/var/www': ensure =&gt; directory }
</span><span class='line'>  glusterfs::mount { '/var/www':
</span><span class='line'>    device =&gt; $::hostname ? {
</span><span class='line'>      'gluster2' =&gt; '192.168.1.38:/gv0',
</span><span class='line'>    }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>What does all that do? Starting from the top:</p>

<ul>
<li> The <code>basenode</code> class does all your basic configuration across all your hosts. Mine actually does a lot more, but these are the relevant parts.</li>
<li> The <code>glusternode</code> class is shared between all your GlusterFS nodes. This is where all your Server configuration is.</li>
<li> Configures LVM

<ul>
<li>Defines the Volume Group &#8220;vg0&#8221; with the Physical Volume <code>/dev/sdb</code></li>
<li>Creates a Logical Volume &#8220;gv0&#8221; for GlusterFS use and make it 7GB</li>
</ul>
</li>
<li> Configures the file system

<ul>
<li>Creates the directory <code>/export/gv0</code></li>
<li>Formats the LV created previously with XFS (installs the package if necessary)</li>
<li>Mounts the LV at <code>/export/gv0</code></li>
</ul>
</li>
</ul>


<p>This is now all ready for the GlusterFS module to do its stuff. All this happens in those last two sections.</p>

<ul>
<li> The class <code>glusterfs::Server</code> sets up the peering between the two hosts. This will actually generate a errors, but do not worry. This because gluster1 successfully peers with gluster2. As a result gluster2 fails to peer with gluster1 as they are already peered.</li>
<li> Now <code>glusterfs::volume</code> creates a replicated volume, having first ensured that the LV is mounted correctly.</li>
<li> All this is then included in the node declarations for <code>gluster1</code> and <code>gluster2</code>.</li>
</ul>


<p>All that creates the server very nicely. It will need a few passes to get everything in place, while giving a few red herring errors. It should would however, all the errors are there in the README for the GlusterFS module in PuppetForge, so do not panic.</p>

<p>A multi-petabyte scale-out storage system is pretty useless if the data cannot be read by anything. So lets use those nodes and mount the volume. This could also be a separate node (but once again I am being lazy) the process will be exactly the same.</p>

<ul>
<li> Create a mount point for it ( `file {&#8216;/var/www&#8217;: ensure => directory }</li>
<li> Define your <code>glusterfs::mount</code> using any of the hosts in the cluster.</li>
</ul>


<p>Voila, that should all pull together and give you a fully automated GlusterFS set up. The sort of scale that GlusterFS can reach makes this sort of automation absolutely essential in my opinion. This should be relatively easy to convert to Chef or Ansible, whatever takes your fancy. I have just used Puppet because of my familiarity with it.</p>

<p>This is only one way of doing this, and I make no claims to being the most adept Puppet user in the world. All I hope to achieve is that someone finds this useful. Courteous comments welcome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dell Announces VRTX]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/06/04/dell-announces-vrtx/"/>
    <updated>2013-06-04T22:15:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/06/04/dell-announces-vrtx</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://en.community.dell.com/cfs-file.ashx/__key/communityserver-blogs-components-weblogfiles/00-00-00-37-45/6886.vrtx.JPG"> Dell has announced the new PowerEdge VRTX (pronounced Vertex). The name comes from a vertex being &#8220;the intersection of multiple lines&#8221;, alluding to this being a mixture of a rack server, a blade server and a SAN.</p>

<!-- more -->


<p>It is aimed at branch offices, so it contains 4 servers, storage, networking and (unusually) the ability to add PCI-e cards (up to 8, including 3 FH/FL). These cards can be connected to which ever server you want. These features put in competition with the HP C3000 and the Supermicro OfficeBlade.</p>

<p>The other 2 are basically standard blade chassis that have been given quiet fans and IEC power connectors. You can pick and choose storage, PCI-E and compute blades depending on your needs. They also have the full array of networking options: anything from 2 1Gb uplinks to full on 40GB QDR infiniband. VRTX on the other hand is a fixed configuration of a 2U SAS array (either 2.5&#8221; or 3.5&#8221; disks) and 4 compute servers. You can add PCI-e cards, but support is limited. Basically, it expands the limited networking available in the blades themselves (no 10Gb at launch, max of 8x 1Gb uplink with no redundant fabric). There is support for a GPU, but it is AMD only with  no Nvidia Tesla support.</p>

<p>So what we have is a system that takes the same amount of space as it competitors and is less flexible. So why would you want it? In several cases I have wanted something that would give me a simple solution to run VMware (or similar) properly (i.e. shared storage and at least 2 nodes) and go in the corner of the office on a standard plug. The other solutions can do this with a bit of thought (more so with the Supermicro), but the VRTX will do that out-of-the-box.</p>

<p>If I could make 1 request of Dell, it would be to do a &#8220;VRTX lite&#8221; that drops the PCI-e slots and (perhaps) halves the number of disks and servers. To get a pair of computer servers and a small SAN in a 4 bay NAS sized box would be awesome for many a SMB branch office.</p>

<iframe width="640" height="360" src="http://www.youtube.com/embed/16IlDQnIMrk?rel=0" frameborder="0" allowfullscreen></iframe>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jellybean and OpenVPN]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/05/30/jellybean-and-openvpn/"/>
    <updated>2013-05-30T22:14:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/05/30/jellybean-and-openvpn</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://openvpn.net/templates/telethra/img/ovpntech_logo-s.png">Setting up the server is well documented elsewhere, the <a href="http://openvpn.net/index.php/open-source/documentation/howto.html#quick">official howto</a> works nicely for me. I use a Virtual TUN network (routed) with clients connecting via UDP 1194, with all the network config pushed out by the server. Follow the howto and you will get that at the end.</p>

<!-- more -->


<p>When you create the key for your Jellybean client, create a PKCS12 certificate. This just means using the <code>build-key-pkcs12</code> script instead of <code>build-key</code>. Copy that .p12 key to the root of the SD card in your phone.</p>

<p>Now you can make that certificate available for use by the OpenVPN client. Open <em>Setting -> Security -> Install from SD Card</em> and choose the .p12 file you just copied there.</p>

<p>Install <a href="http://code.google.com/p/ics-openvpn/">OpenVPN for Android/ICS-openvpn</a>. In that create a new profile with a suitable name. Under &#8220;Basic&#8221; configure the <em>Server Address</em> and choose your certificate.</p>

<p>The end&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Enable Developer Options on Android Jellybean]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/05/29/enable-developer-options-on-android-jellybean/"/>
    <updated>2013-05-29T21:13:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/05/29/enable-developer-options-on-android-jellybean</id>
    <content type="html"><![CDATA[<p><img class="right" src="http://www.android.com/images/whatsnew/jb-new-logo.png" title="" >This was weird! I just updated my venerable ZTE Blade to Cyanogenmod 10.1 (Jellybean). I flashed it, then rebooted having completely forgotten to to install GApps. No problem, reboot into Clockmod Recovery and install them. Promlem: no option to reboot to recovery.</p>

<!-- more -->


<p>It turns out that you need to enable <em>Advanced reboot</em> in the *Developer Options. Problem where are those options. In Jellybean 4.2 they are hidden.</p>

<ul>
<li>Open up <em>Settings</em> -> <em>About Phone</em></li>
<li>Find the entry for <em>Build number</em></li>
<li>Tap on it 7 times (honest), after the 3rd it will start to count down.</li>
</ul>


<p>Now you will have a new option under <em>Settings</em> for <em>Developer Options</em> in which you can turn on *Advanced Reboot&#8221;</p>

<p>For anyone who has a ZTE Blade and would like to get the latest and greatest Android on it, the files are <a href="https://copy.com/Dqx4qRjgs6KK">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EMC ViPR thoughts]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/05/13/emc-vipr-thoughts/"/>
    <updated>2013-05-13T21:45:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/05/13/emc-vipr-thoughts</id>
    <content type="html"><![CDATA[<p>I have been a little slow on the uptake on this one. I would like to say it is because I was carefully digesting the information, but that is not true; the reality is that I have just had 2 5 day weekends in 2 weeks :-).</p>

<!-- more -->


<p>The big announcement at this years EMC World is ViPR. Plenty of people with far bigger reputations than me in the industry have already made their comments:</p>

<ul>
<li><a href="http://virtualgeek.typepad.com/virtual_geek/2013/05/storage-virtualization-platform-re-imagined.html">Chad Sakac</a> has really good and deep, but long.</li>
<li><a href="http://chucksblog.emc.com/chucks_blog/2013/05/introducing-emc-vipr-a-breathtaking-approach-to-software-defined-storage.html">Chuck Hollis</a> is nowhere near as technical but (as is normal for Chuck) sells it beautifully</li>
<li><a href="http://blog.scottlowe.org/2013/05/06/very-early-thoughts-about-emc-vipr/">Scott Lowe</a> has an excellent overview</li>
<li><a href="http://h30507.www3.hp.com/t5/Around-the-Storage-Block-Blog/ViPR-or-Vapor-The-Software-Defined-Storage-saga-continues/ba-p/138013?utm_source=feedly#.UZCd_covj3w">Kate Davies</a> gives HP&#8217;s take on it, which I sort of agree with, but not completely. As she says, the StoreAll VSA is not really in the same market, but I think it is the closest thing HP have so comparisons will always be drawn.</li>
</ul>


<p>ViPR is EMC&#8217;s response to two major storage problems:
1.   Storage is missing some sort of abstraction layer, particularly for management (the Control Plane).
1.   There is more to storage than NFS and iSCSI. As well as NAS/SAN we now have multiple forms of object stores, plus important non-POSIX file systems such as HDFS.</p>

<p>Another problem I would add is that of <em>Openness</em>. For now there is not really any protocols for managing multiple arrays from different manufacturers, even at a basic level. They have been attempts in the past (SMI-S), but they have never taken off. ViPR attacks that problem as well, sort of.</p>

<p>In some respects I am quite excited about ViPR. The ability to completely abstract the management of my storage is potentially very powerful. For now it is not really possible to integrate storage with Configuration Management tools. ViPR gives all supported arrays a REST API, thus it would be very simple to create bindings for the scripting language of your choice. Low and behold, a Puppet module to manage all my storage arrays becomes possible. This very neatly solves problem #1.</p>

<p>This is where my excitement ends however. The problem is that issue of <em>Openness</em> I mentioned above. EMC has gone to great lengths to describe ViPR as open, but the fact remains that it is not. EMC have published the specifications of the REST API, they have also created a plugin interface for third-parties to add their own arrays; this is where it ends however. All development of ViPR is at the mercy of EMC, so why would other vendors support it?</p>

<p>A lot of the management tools in ViPR are already in Openstack Cinder, which supports a much wider range of backends than ViPR at present. In that vendors have a completely open source management layer to develop against. Why would they sell their souls to a competitor? Simple, they will not. EMC exclusive shops will find ViPR to be an excellent way integrating their storage with a DevOps style workflow. Unfortunately my experience is that the sort of organizations that buy EMC (especially the big ones like VMAX) are not really ready for DevOps yet.</p>

<p>Another feature that EMC has been touted is multi-protocol access to your data. Block volumes can be accessed via both iSCSI and FC protocols - nothing really clever there I&#8217;m afraid. Dot Hill has been doing that for several years with the <a href="http://www.dothill.com/wp-content/uploads/2011/08/AssuredSAN-n-3920-3930-C-10.15.11.pdf">AssuredSAN 39x0</a> models (and by extension the the HP P2000 as well). That is also easy enough to do on commodity hardware using  <a href="http://linux-iscsi.org/wiki/Main_Page">LIO target</a> plus a whole lot more. On the file side, it gives you not only access to your data via both CIFS and NFS, but it does add object access to that. They touted this as being very clever, but once again you can already do this using well respected, production proven open source. Glusterfs has an object translator, so that covers that super clever feature. All the data abstraction features it has are already there in in the open source world. If you want object and NAS access to the same peta-byte storage system, you have it in both Glusterfs and Ceph, both of which can easily be managed by CM tools such as Puppet.</p>

<p><span class='pullquote-right' data-pullquote='To be a universal standard it would need to be an open (source) standard'>
EMC has really pushed ViPR in the last couple of weeks, but it fails to impress me. This is a shame, because in general I like EMC&#8217;s products. I don&#8217;t like their marketing, but in their gear does just work. ViPR will probably do well with large EMC/NetApp shops, but it is by no means the ground-breaking product that EMC would have people believe (to be honest, I&#8217;m not sure anything ever is). It can never be the universal gateway to manage our storage, it is too tied in to EMC. To be a universal standard it would need to be an open (source) standard, which is not really part of EMC&#8217;s culture (with the exception of the awesome Razor).
</span></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bamboo Invoice on Centos with Nginx]]></title>
    <link href="http://www.chriscowley.me.uk/blog/2013/04/29/bamboo-invoice-on-centos-with-nginx/"/>
    <updated>2013-04-29T21:16:00+02:00</updated>
    <id>http://www.chriscowley.me.uk/blog/2013/04/29/bamboo-invoice-on-centos-with-nginx</id>
    <content type="html"><![CDATA[<p><a href="http://www.bambooinvoice.org/">BambooInvoice</a> is free Open Source invoicing software intended for small businesses and independent contractors. It is easy to use and creates pretty good looking invoices.</p>

<!-- more -->


<p>It is a simple PHP application that is based on the CodeIgniter framework. This means it is really simple to install on a typically LAMP stack. I however use Nginx and could not find any notes on how to configure it. It is pretty typical you can get most of the way by reading any of the Nginx howto documents on the web. Personally, for PHP apps, I use PHP-FPM, so you could use <a href="http://www.howtoforge.com/installing-nginx-with-php5-and-php-fpm-and-mysql-support-on-centos-6.4">this on Howtoforge</a> to get most of the way. That will get you a working Nginx, PHP and MySQL system.</p>

<p>Download the install file from [http://bambooinvoice.org/] an unzip is in your www folder:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /var/www
</span><span class='line'>wget http://bambooinvoice.org/img/bambooinvoice_089.zip
</span><span class='line'>unzip bambooinvoice_089.zip
</span></code></pre></td></tr></table></div></figure>


<p>You next step is to create a database for it along with a user:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='mysql'><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">bambooinvoice</span> <span class="k">DEFAULT</span> <span class="k">CHARACTER</span> <span class="kt">SET</span> <span class="n">utf8</span><span class="p">;</span>
</span><span class='line'><span class="k">GRANT</span> <span class="k">ALL</span> <span class="k">ON</span> <span class="n">bambooinvoice</span><span class="p">.</span><span class="o">*</span> <span class="k">TO</span> <span class="s1">&#39;bambooinvoice&#39;</span><span class="o">@</span><span class="s1">&#39;localhost&#39;</span> <span class="n">IDENTIFIED</span> <span class="k">BY</span> <span class="s1">&#39;bambooinvoice&#39;</span><span class="p">;</span>
</span><span class='line'><span class="n">FLUSH</span> <span class="n">PRIVILEGES</span><span class="p">;</span>
</span><span class='line'><span class="k">exit</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now you can edit the config files to point at the database:</p>

<figure class='code'><figcaption><span>/var/www/bambooinvoices/bamboo_system_files/application/config/database.php</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='php'><span class='line'><span class="cp">&lt;?php</span>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nb">defined</span><span class="p">(</span><span class="s1">&#39;BASEPATH&#39;</span><span class="p">))</span> <span class="k">exit</span><span class="p">(</span><span class="s1">&#39;No direct script access allowed&#39;</span><span class="p">);</span>
</span><span class='line'><span class="nv">$active_group</span> <span class="o">=</span> <span class="s1">&#39;default&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;hostname&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;username&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bambooinvoice&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;password&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bambooinvoice&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;database&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bambooinvoice&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;dbdriver&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;mysql&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;dbprefix&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;bamboo_&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;active_r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="k">TRUE</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;pconnect&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="k">FALSE</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;db_debug&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="k">TRUE</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;cache_on&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="k">FALSE</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;cachedir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;char_set&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;utf8&#39;</span><span class="p">;</span>
</span><span class='line'><span class="nv">$db</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">][</span><span class="s1">&#39;dbcollat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;utf8_general_ci&#39;</span><span class="p">;</span>
</span><span class='line'><span class="cp">?&gt;</span><span class="x"></span>
</span></code></pre></td></tr></table></div></figure>


<p>Next you need set the base_url in <code>/var/www/bambooinvoices/bamboo_system_files/application/config/config.php</code>. Nothing else is essential in that file, but read the docs in the ZIP file to see what else you want to change.</p>

<p>Now the all important bit.</p>

<figure class='code'><figcaption><span>/etc/nginx/conf.d/bamboo.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class='nginx'><span class='line'><span class="k">server</span> <span class="p">{</span>
</span><span class='line'>    <span class="kn">listen</span> <span class="mi">80</span><span class="p">;</span>
</span><span class='line'>    <span class="kn">server_name</span> <span class="s">bamboo.example</span><span class="p">;</span>
</span><span class='line'>    <span class="kn">root</span> <span class="s">/var/www/bambooinvoice/</span><span class="p">;</span>
</span><span class='line'>    <span class="kn">index</span> <span class="s">index.php</span> <span class="s">index.html</span><span class="p">;</span>
</span><span class='line'>    <span class="kn">access_log</span>              <span class="s">/var/log/nginx/bamboo_access.log</span><span class="p">;</span>
</span><span class='line'>    <span class="kn">error_log</span>               <span class="s">/var/log/nginx/bamboo_error.log</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="kn">location</span> <span class="p">=</span> <span class="s">/robots.txt</span> <span class="p">{</span>
</span><span class='line'>        <span class="kn">allow</span> <span class="s">all</span><span class="p">;</span>
</span><span class='line'>        <span class="kn">log_not_found</span> <span class="no">off</span><span class="p">;</span>
</span><span class='line'>        <span class="kn">access_log</span> <span class="no">off</span><span class="p">;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>    <span class="c1"># Deny all attempts to access hidden files such as .htaccess, .htpasswd, .DS_Store (Mac).</span>
</span><span class='line'>    <span class="kn">location</span> <span class="p">~</span> <span class="sr">/\.</span> <span class="p">{</span>
</span><span class='line'>        <span class="kn">deny</span> <span class="s">all</span><span class="p">;</span>
</span><span class='line'>        <span class="kn">access_log</span> <span class="no">off</span><span class="p">;</span>
</span><span class='line'>        <span class="kn">log_not_found</span> <span class="no">off</span><span class="p">;</span>
</span><span class='line'>     <span class="p">}</span>
</span><span class='line'>     <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
</span><span class='line'>         <span class="kn">try_files</span> <span class="nv">$uri</span> <span class="nv">$uri/</span> <span class="s">/index.php</span><span class="nv">$request_uri</span> <span class="s">/index.php</span><span class="p">;</span>
</span><span class='line'>     <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>     <span class="kn">location</span> <span class="p">~</span> <span class="sr">\.php($|/)</span> <span class="p">{</span>
</span><span class='line'>         <span class="kn">try_files</span> <span class="nv">$uri</span> <span class="p">=</span><span class="mi">404</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">fastcgi_pass</span> <span class="n">127.0.0.1</span><span class="p">:</span><span class="mi">9000</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">include</span> <span class="s">/etc/nginx/fastcgi_params</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">fastcgi_index</span> <span class="s">index.php</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">set</span> <span class="nv">$script</span> <span class="nv">$uri</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">set</span> <span class="nv">$path_info</span> <span class="s">&quot;&quot;</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">if</span> <span class="s">(</span><span class="nv">$uri</span> <span class="p">~</span> <span class="sr">&quot;^(.+\.php)(/.+)&quot;)</span> <span class="p">{</span>
</span><span class='line'>             <span class="kn">set</span> <span class="nv">$script</span> <span class="nv">$1</span><span class="p">;</span>
</span><span class='line'>             <span class="kn">set</span> <span class="nv">$path_info</span> <span class="nv">$2</span><span class="p">;</span>
</span><span class='line'>         <span class="p">}</span>
</span><span class='line'>         <span class="kn">fastcgi_param</span> <span class="s">URI</span> <span class="nv">$uri</span><span class="p">;</span>
</span><span class='line'>         <span class="c1"># Next two lines are fix the 502 (Bad gateway) error</span>
</span><span class='line'>         <span class="kn">fastcgi_buffers</span> <span class="mi">8</span> <span class="mi">16k</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">fastcgi_buffer_size</span> <span class="mi">32k</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>         <span class="kn">fastcgi_param</span> <span class="s">PATH_INFO</span> <span class="nv">$path_info</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">fastcgi_param</span> <span class="s">SCRIPT_NAME</span> <span class="nv">$script</span><span class="p">;</span>
</span><span class='line'>         <span class="kn">fastcgi_param</span> <span class="s">SCRIPT_FILENAME</span> <span class="nv">$document_root$script</span><span class="p">;</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>At first glance, there is nothing out of the ordinary. This is pretty much what Howtoforge gives you. Look more closely and I have added the 3 lines 39-41. This solves a gateway problem I had when creating a client.</p>
]]></content>
  </entry>
  
</feed>
