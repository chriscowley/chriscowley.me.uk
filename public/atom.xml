<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Just Another Linux Blog]]></title>
  <link href="http://http://warm-sword-7449.herokuapp.com//atom.xml" rel="self"/>
  <link href="http://http://warm-sword-7449.herokuapp.com//"/>
  <updated>2012-07-17T13:26:08+01:00</updated>
  <id>http://http://warm-sword-7449.herokuapp.com//</id>
  <author>
    <name><![CDATA[Chris Cowley]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mirror a Subversion repo with svnsync]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/07/17/mirror-a-subversion-repo-with-svnsync/"/>
    <updated>2012-07-17T12:03:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/07/17/mirror-a-subversion-repo-with-svnsync</id>
    <content type="html"><![CDATA[<p>The basic idea is that everytime a change happens on the master, it gets pushed to the slave. In this set up it will <em>not</em> get you any more capacity; you cannot commit back to the slave. If you do it will get out of sync, resulting in a <em>split brain</em> situation. This is what we sysadmins call a &#8220;bad thing&#8221;. I am doing this in order to have <a href="http://www.atlassian.com/software/fisheye/overview" target="_blank">Atlassian Fisheye</a> can scan the repository without having to go over the network. The basic layout is:</p>

<p><img class="center" src="http://http://warm-sword-7449.herokuapp.com//images/svnsync.png"></p>

<p>First the master needs to be able to send the data to the slave without any user interaction. On both the slave create a user to perform the sync:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>useradd svnsync</span></code></pre></td></tr></table></div></figure>


<p>On the master, I use https to access my repositories. This means that all my hook scripts run as the apache user. Change to that user with <code>sudo su -s /bin/bash - apache</code></p>

<p>Create an ssh key-pair (<code>ssh-keygen</code>) and add the contents of <code>~apache\.ssh\id_rsa.pub</code> on the master to <code>~svnsync/.ssh/authorized_keys2</code> on the slave.</p>

<p>Now you can push push data to the slave without a password. Test it by running:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh svnsync@&lt;slave&gt;</span></code></pre></td></tr></table></div></figure>


<h2>On Slave</h2>

<p>Create a new repository to store what gets pushed to it</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>svnadmin create --fs-type=fsfs /var/local/svnsync/&lt;reponame&gt;
</span><span class='line'>chown -Rv svnsync:svnsync /var/local/svnsync/&lt;reponame&gt;</span></code></pre></td></tr></table></div></figure>


<p>The process will need to make modifications to the properties, so you need to enable that. Put the following into <code>/var/local/svnsync/&lt;reponame&gt;/hooks/pre-revprop-change</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/sh
</span><span class='line'>USER="$3"
</span><span class='line'>
</span><span class='line'>if [ "$USER" = "svnsync" ]; then exit 0; fi
</span><span class='line'>
</span><span class='line'>echo "Only the svnsync user can change revprops" &gt;&2
</span><span class='line'>exit 1</span></code></pre></td></tr></table></div></figure>


<p>Finally make it executable with</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>chmod +x /var/local/svnsync/&lt;reponame&gt;/hooks/pre-revprop-change</span></code></pre></td></tr></table></div></figure>


<h2>On Master</h2>

<p>First initialize the transfer and do the initial population. Do all this as the apache user again.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>svnsync init --username svnsync \
</span><span class='line'>    svn+ssh://svnsync@vm-slp-is-rc/var/local/svnsync/&lt;reponame&gt; \
</span><span class='line'>    file:///var/svn/&lt;reponame&gt;</span></code></pre></td></tr></table></div></figure>


<p>Now we need to configure the Master repo to push all changes to the slave. Create a post-commit hook script containing</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/bash
</span><span class='line'>svnsync --username svnsync --non-interactive sync \
</span><span class='line'>    svn+ssh://svnsync@vm-slp-is-rc/var/local/svnsync/&lt;reponame&gt;</span></code></pre></td></tr></table></div></figure>


<p>Finally create another hook script to keep revision properties in sync in <code>/var/svn/&lt;reponame&gt;/hooks/post-revprop-change</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/bash
</span><span class='line'>REPOS="$1"
</span><span class='line'>REV="$2"
</span><span class='line'>USER="$3"
</span><span class='line'>PROPNAME="$4"
</span><span class='line'>ACTION="$5"
</span><span class='line'>
</span><span class='line'>svnsync --username svnsync --non-interactive copy-revprops \
</span><span class='line'>    svn+ssh://svnsync@vm-slp-is-rc/var/local/svnsync/&lt;reponame&gt; $REV && \
</span><span class='line'>    exit 0</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fixed my gihub repo list]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/07/03/fixed-my-gihub-repo-list/"/>
    <updated>2012-07-03T20:54:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/07/03/fixed-my-gihub-repo-list</id>
    <content type="html"><![CDATA[<p>My Github repo list has not worked as all since I moved over to Octopress. This evening I though I would have a little look into it.</p>

<p>It turned out that GitHub has <a href="https://github.com/blog/1160-github-api-v2-end-of-life" target="_blank">depreciated the version 1 and 2 APIs</a>. Octopress was using version 2, so I have made a little change.</p>

<div><script src='https://gist.github.com/3042647.js?file='></script>
<noscript><pre><code>diff --git a/source/javascripts/github.js b/source/javascripts/github.js
index 678775a..8b79dad 100644
--- a/source/javascripts/github.js
+++ b/source/javascripts/github.js
@@ -10,15 +10,15 @@ var github = (function(){
   return {
     showRepos: function(options){
       $.ajax({
-          url: &quot;http://github.com/api/v2/json/repos/show/&quot;+options.user+&quot;?callback=?&quot;
+          url: &quot;https://api.github.com/users/&quot;+options.user+&quot;/repos?callback=?&quot;
         , type: 'jsonp'
         , error: function (err) { $(options.target + ' li.loading').addClass('error').text(&quot;Error loading feed&quot;); }
         , success: function(data) {
           var repos = [];
-          if (!data || !data.repositories) { return; }
-          for (var i = 0; i &lt; data.repositories.length; i++) {
-            if (options.skip_forks &amp;&amp; data.repositories[i].fork) { continue; }
-            repos.push(data.repositories[i]);
+          if (!data || !data.data) { return; }
+          for (var i = 0; i &lt; data.data.length; i++) {
+            if (options.skip_forks &amp;&amp; data.data[i].fork) { continue; }
+            repos.push(data.data[i]);
           }
           repos.sort(function(a, b) {
             var aDate = new Date(a.pushed_at).valueOf(),</code></pre></noscript></div>


<p>According to <a href="https://github.com/imathis/octopress/issues/620" target="_blank">this issue</a> there will be a fix in <a href="https://github.com/imathis/octopress/tree/2.1" target="_blank" >Octopress 2.1</a>. However, this patch will keep things working until Brandon Mathis moves it into the master branch. Of course that issue also highlighted the fact that I had just re-invented the wheel :(</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Excellent seminar given by a friend of mine]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/07/03/excellent-seminar-given-by-a-friend-of-mine/"/>
    <updated>2012-07-03T15:01:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/07/03/excellent-seminar-given-by-a-friend-of-mine</id>
    <content type="html"><![CDATA[<p>My friend <a target="_blank" href="http://twitter.com/#!/bobscape">Rob Borley</a> was talking at this year&#8217;s <a href="http://iwmw.ukoln.ac.uk/" target="_blank">International Web Management Workshow</a>. He actually got voted &#8220;best talk&#8221; - which was nice.</p>

<p>Anyone who even touches on Web vs mobile development should really watch it. His comes out with some very good idea.</p>

<iframe src="http://player.vimeo.com/video/44618744?title=0&amp;byline=0&amp;portrait=0&amp;color=ff9933" width="400" height="300" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing PostgreSQL on Fedora 17]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/06/23/installing-postgresql-on-fedora-17/"/>
    <updated>2012-06-23T13:02:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/06/23/installing-postgresql-on-fedora-17</id>
    <content type="html"><![CDATA[<p>With the new systemd this now requires a couple of manual steps.</p>

<p>Obviously we start by installing the RPMS themselves:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo yum install postgresql-server postgresql</span></code></pre></td></tr></table></div></figure>


<p>If you were to now try and start the server it would fail as there is no database. The old SysV init script had an <em>initdb</em> option, but this no longer exists in the systemd service script. This means that you need to initialise the database manually:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo -u postrgres initdb -D /var/lib/pgsql/</span></code></pre></td></tr></table></div></figure>


<p>You can now start the service and enable it permanently</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo service postgresql start
</span><span class='line'>sudo chkconfig postgresql on</span></code></pre></td></tr></table></div></figure>


<p>Now you can enter the database as the postgres <em>superuser</em>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo -u postgres psql -d postgres</span></code></pre></td></tr></table></div></figure>


<p>Finally create your user and associated database</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE ROLE "testAdmin" LOGIN PASSWORD 'testAdmin';
</span><span class='line'>CREATE DATABASE "testDB" WITH ENCODING='UTF8' OWNER="testAdmin";
</span><span class='line'>\q</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Skype video on Fedora 64bit]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/04/18/skype-video-on-fedora-64bit/"/>
    <updated>2012-04-18T15:53:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/04/18/skype-video-on-fedora-64bit</id>
    <content type="html"><![CDATA[<p>Install Skype – I used <a href="http://slayachronicles.blogspot.co.uk/2012/03/installing-skype-on-fedora-16-64-bit.html" target="_blank" >these</a> instructions. This will seem to get everything working, but video will just give you a black screen and no error message. This is because Skype is 32 bit and you webcam driver is 64 bit. Make sure you have libv4l.i686 installed.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo yum install libv4l.i686</span></code></pre></td></tr></table></div></figure>


<p>Now create a wrapper script to launch it with a custom environment. I put it in <em>/usr/local/bin/skype</em></p>

<figure class='code'><figcaption><span> (skype)</span> <a href='http://http://warm-sword-7449.herokuapp.com//downloads/code/skype'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'><span class="nv">LD_PRELOAD</span><span class="o">=</span>/usr/lib/libv4l/v4l1compat.so  /usr/bin/skype
</span></code></pre></td></tr></table></div></figure>


<p>This will now get loaded before the main Skype executable and you will have a working video device.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Learning Experience]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/04/16/a-learning-experience/"/>
    <updated>2012-04-16T20:30:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/04/16/a-learning-experience</id>
    <content type="html"><![CDATA[<p>How many times have you installed/updated a bit of software and read the line “Please take a back up” or something to that effect? 99 times out of a hundred, you will just continue and ignore it.</p>

<p>Today I had a reminder of why it is import to do so. I did a routine plug-in upgrade on our Jira installation (Customware Salesforce connector for those who want to know). I have done this several times, I had tested it in our Dev installation I was 100% confident it would work as expected. However, I actually decided to take a backup anyway.</p>

<p>I ran the upgrade in the production environment and re-indexed. Nothing out of the ordinary. 10% of the way into the index it fell over. Jira’s database was gone! Fortunately I was able to restore from my backup and at worst a comment or two was lost, but that still caused significant downtime.</p>

<p>I had done everything I could to make sure the upgrade would go smoothly, but it still did not. That is why software vendors always tell you to take a backup before even the smallest change – DO IT!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PyCurl and self-signed SSL certificates]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/04/05/pycurl-and-self-signed-ssl-certificates/"/>
    <updated>2012-04-05T16:50:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/04/05/pycurl-and-self-signed-ssl-certificates</id>
    <content type="html"><![CDATA[<p>At <a href="http://www.snellgroup.com" target="_blank">Snell</a> we make heavy use of self-signed certificates for internal websites, such as the R&amp;D wiki. Active Directory makes it easy for us to make this transparent to the users, those that use Firefox/Chrome can find our well-published instructions to add the CA certificate to their own browsers.</p>

<p>Today I was writing a script to that pulls lots of attachments off our Confluence wiki, which we access through SSL using one of those certificates. Of course PyCurl  moaned that it could not verify the host, but I did not care – I know it is the right host!</p>

<p>Finding documentation both on SSL and PyCurl is problematic at best. OpenSSL’s documentation it complete, but could not be more unreadable if written by a right-handed doctor using a broken crayon with his left-hand; pyCurl’s documentation is non-existent.</p>

<p>After an hour of Google-Fu and DuckDuckGo-Fu I finally managed to do what I wanted:</p>

<figure class='code'><figcaption><span> (pycurl_ssl.py)</span> <a href='http://http://warm-sword-7449.herokuapp.com//downloads/code/pycurl_ssl.py'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='py'><span class='line'><span class="c">#!/usr/bin/env python</span>
</span><span class='line'><span class="n">downloadedFile</span> <span class="o">=</span> <span class="s">&quot;/tmp/stuff&quot;</span>
</span><span class='line'><span class="n">outfile</span> <span class="o">=</span> <span class="nb">file</span><span class="p">(</span><span class="n">downloadedFile</span><span class="p">,</span> <span class="s">&#39;wb&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">someurl</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">com</span>
</span><span class='line'><span class="n">c</span> <span class="o">=</span> <span class="n">pycurl</span><span class="o">.</span><span class="n">Curl</span><span class="p">()</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">setopt</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">URL</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">setopt</span><span class="p">(</span><span class="n">pycurl</span><span class="o">.</span><span class="n">USERPWD</span><span class="p">,</span> <span class="s">&quot;</span><span class="si">%s</span><span class="s">:</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">))</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">setopt</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">WRITEFUNCTION</span><span class="p">,</span> <span class="n">outfile</span><span class="o">.</span><span class="n">write</span><span class="p">)</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">setopt</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">SSL_VERIFYPEER</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c"># That is you key line for this purpose!</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">perform</span><span class="p">()</span>
</span><span class='line'><span class="n">c</span><span class="o">.</span><span class="n">close</span>
</span></code></pre></td></tr></table></div></figure>


<p>There you go!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Highly Available NFS/NAS]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/03/19/highly-available-nfs-slash-nas/"/>
    <updated>2012-03-19T16:59:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/03/19/highly-available-nfs-slash-nas</id>
    <content type="html"><![CDATA[<p>Take 2 Centos Servers (nfs1 and nfs2 will do nicely) and install ELrepo and EPEL on them both:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install \
</span><span class='line'>    http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-5.noarch.rpm \
</span><span class='line'>    http://elrepo.org/elrepo-release-6-4.el6.elrepo.noarch.rpm --nogpgcheck</span></code></pre></td></tr></table></div></figure>


<p>Each of them should ideally have 2 NICS, with the secondary ones just used for DRBD sync purposes. We’ll give these the address 10.0.0.1/32 and 10.0.0.2/32.</p>

<p>I am also assuming that you have disabled the firewall and SELinux – I do not recommend that for production, but for testing it is fine.</p>

<h2>DRBD Configuration</h2>

<p>Install DRBD 8.4 on the both:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install drbd84-utils kmod-drbd84</span></code></pre></td></tr></table></div></figure>


<p>On each node the file /etc/drbd.d/global_common.conf should contain:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>global {
</span><span class='line'>  usage-count yes;
</span><span class='line'>}
</span><span class='line'>common {
</span><span class='line'>  net {
</span><span class='line'>    protocol C;
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>and /etc/drbd.d/main.res should contain:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource main {
</span><span class='line'>  on nfs1 {
</span><span class='line'>    device    /dev/drbd0;
</span><span class='line'>    disk      /dev/sdb;
</span><span class='line'>    address   10.0.0.1:7788;
</span><span class='line'>    meta-disk internal;
</span><span class='line'>  }
</span><span class='line'>  on nfs2 {
</span><span class='line'>    device    /dev/drbd0;
</span><span class='line'>    disk      /dev/sdb;
</span><span class='line'>    address   10.0.0.2:7788;
</span><span class='line'>    meta-disk internal;
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>On both nodes you will need to create the resource metadata:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>drbdadm create-md main</span></code></pre></td></tr></table></div></figure>


<p>and start the daemons</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service drbd start
</span><span class='line'>chkconfig drbd on</span></code></pre></td></tr></table></div></figure>


<p>Now <code>service drbd status</code> will give you:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>drbd driver loaded OK; device status:
</span><span class='line'>version: 8.4.1 (api:1/proto:86-100)
</span><span class='line'>GIT-hash: 91b4c048c1a0e06777b5f65d312b38d47abaea80 build by dag@Build64R6, 2011-12-21 06:08:50
</span><span class='line'>m:res   cs         ro                   ds                         p  mounted  fstype
</span><span class='line'>0:main  Connected  Secondary/Secondary  Inconsistent/Inconsistent  C</span></code></pre></td></tr></table></div></figure>


<p>Both devices or secondary and inconsistent, this is normal at this stage. Choose a node to be your primary and run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>drbdadm primary --force main</span></code></pre></td></tr></table></div></figure>


<p>And it start sync’ing, which will take a long time. You can temporarily make it faster with (on one node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>drbdadm disk-options --resync-rate=110M main</span></code></pre></td></tr></table></div></figure>


<p>Put it back again with drbdadm adjust main</p>

<p>On your primary node you can now create a fiiesystem. I’m using ext4 for no good reason other than it being the default. Use whatever you are most comfortable with.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkfs.ext4 /dev/drbd0</span></code></pre></td></tr></table></div></figure>


<h2>Configure NFS</h2>

<p>If you diid a minimal Centos install, then you willl need to install the nfs-utils package (yum install nfs-utils). Prepare your mount points and exports on both servers:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir /drbd
</span><span class='line'>echo "/drbd/main *(rw)" >> /etc/exports</span></code></pre></td></tr></table></div></figure>


<p>Now we do the actual NFS set up. We previously choose nfs1 as our master when you used it to trigger the initial sync. On nfs1 mount the replicated volumes, move the NFS data to it, then create symlinks to our replicated data.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount /dev/drbd0 /drbd
</span><span class='line'>mkdir /drbd/main
</span><span class='line'>mv /var/lib/nfs/ /drbd/
</span><span class='line'>ln -s /drbd/nfs/ /var/lib/nfs
</span><span class='line'>umount /drbd</span></code></pre></td></tr></table></div></figure>


<p>If you get errors about not bring able to remove directories in /var/lib/nfs do not worry.</p>

<p>Now a little preparation on nfs2:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mv /var/lib/nfs /var/lib/nfs.bak
</span><span class='line'>ln -s /drbd/nfs/ /var/lib/nfs</span></code></pre></td></tr></table></div></figure>


<p>This will create a broken symbolic link, but it will be fixed when everything fails over.</p>

<h2>Heartbeat Configuration</h2>

<p>Heartbeat is in the EPEL repository, so enable that and install it on both nodes:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum -y install heartbeat</span></code></pre></td></tr></table></div></figure>


<p>Make sure that <em>/etc/ha.d/ha.cf</em> contains:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>keepalive 2
</span><span class='line'>deadtime 30
</span><span class='line'>bcast eth0
</span><span class='line'>node nfs1 nfs2</span></code></pre></td></tr></table></div></figure>


<p>The values in node should be whatever <code>uname -n</code> returns.</p>

<p>Now create <em>/etc/ha.d/haresources</em>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nfs1 IPaddr::10.0.0.100/24/eth0 drbddisk::main Filesystem::/dev/drbd0::/drbd::ext4 nfslock nfs</span></code></pre></td></tr></table></div></figure>


<p>That is a little cryptic, so I’ll explain; nfs1 is the primary node, IPaddr sets up a floating address on eth0 that our clients will connect to. This has a resource drbddisk::main bound to it, which sets our main to resource to primary on nfs1. Filesystem mounts /dev/drbd0 at /drbd on nfs1. Finally the the services nfslock and nfs are started on nfs1.</p>

<p>Finally, it needs an authentication file in /etc/ha.d/authkeys, which should be chmod’ed to 600 to be only readable by root.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>auth 3
</span><span class='line'>3 md5 mypassword123</span></code></pre></td></tr></table></div></figure>


<p>You should also make sure that nfslock and nfs do not start up by themselves:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>chkconfig nfs off
</span><span class='line'>chkconfig nfslock off</span></code></pre></td></tr></table></div></figure>


<p>Now you can start heartbeat and check it is working:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>service heartbeat start
</span><span class='line'>chkconfig heartbeat on</span></code></pre></td></tr></table></div></figure>


<h2>Testing</h2>

<p>Running <code>ifconfig</code> on nfs1 should give you something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>eth0      Link encap:Ethernet  HWaddr 52:54:00:84:73:BD  
</span><span class='line'>          inet addr:10.0.0.1  Bcast:10.0.0.255  Mask:255.255.255.0
</span><span class='line'>          inet6 addr: fe80::5054:ff:fe84:73bd/64 Scope:Link
</span><span class='line'>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
</span><span class='line'>          RX packets:881922 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:1302012 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:1000
</span><span class='line'>          RX bytes:239440621 (228.3 MiB)  TX bytes:5791818459 (5.3 GiB)
</span><span class='line'>
</span><span class='line'>eth0:0    Link encap:Ethernet  HWaddr 52:54:00:84:73:BD  
</span><span class='line'>          inet addr:10.0.0.100  Bcast:10.0.0.255  Mask:255.255.255.0
</span><span class='line'>          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
</span><span class='line'>
</span><span class='line'>lo        Link encap:Local Loopback  
</span><span class='line'>          inet addr:127.0.0.1  Mask:255.0.0.0
</span><span class='line'>          inet6 addr: ::1/128 Scope:Host
</span><span class='line'>          UP LOOPBACK RUNNING  MTU:16436  Metric:1
</span><span class='line'>          RX packets:2 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>          TX packets:2 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>          collisions:0 txqueuelen:0
</span><span class='line'>          RX bytes:224 (224.0 b)  TX bytes:224 (224.0 b)</span></code></pre></td></tr></table></div></figure>


<p>Note an entry for <em>eth0:0</em> has miraculously appeared.</p>

<p>Also <code>df</code> should include the entry:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/dev/drbd0             20G  172M   19G   1% /drbd</span></code></pre></td></tr></table></div></figure>


<p>Reboot nfs1 and the services should appear on nfs2.</p>

<p>Connect an NFS client to you floating address (10.0.0.100) and you should be able to kill the live node and it will carry on.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Music Player Daemon in Fedora]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/03/16/music-player-daemon-in-fedora/"/>
    <updated>2012-03-16T22:04:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/03/16/music-player-daemon-in-fedora</id>
    <content type="html"><![CDATA[<p>This should have nice and simple, but there was a little gotcha (for me anyway).</p>

<p>First install the RPMFusion repositories:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum localinstall --nogpgcheck \
</span><span class='line'>    http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-stable.noarch.rpm \
</span><span class='line'>    http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-stable.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<p>Now you can install MPD and a simple client with</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install mpd mpc</span></code></pre></td></tr></table></div></figure>


<p>By default it looks in <em>/var/lib/mpd/music</em> which strikes me as reasonable, so copy some music there. Now comes the bit that caught me out; you will need to update is library:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mpc update</span></code></pre></td></tr></table></div></figure>


<p>A lot of documentation on the net talks about running <code>mpd –create-db</code>, but this is now depreciated. I eventually found this out on Arch Linux’s wiki.</p>

<p>Connect a client and listen to your music – I’m using gmpc (<code>yum install gmpc</code>) which is very feature rich, but if you want something simpler, try Sonata (<code>yum install sonata</code>) or even <em>mpc</em> itself. Finally you can also use you MPDroid on your phone.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Back to basics]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/02/22/back-to-basics/"/>
    <updated>2012-02-22T13:00:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/02/22/back-to-basics</id>
    <content type="html"><![CDATA[<p>I have been a Sys Admin for quite a while now. Specialising in Linux means that I am often called upon to be a “jack of all trades, master of many”. In the last week I have touched upon storage, multiple programming languages (Bash, PHP, Python, Ruby and Java), Linux, Exchange, Tomcat, Virtualization and Systems architecture. I am sure the list could go on … and on … and on …</p>

<p>There is however something that I feel I am missing. Before I was in my current post, I was more of a developer. I did a lot of Shell scripting, but also ADA and C/C++. Nowadays I do not do that, which is a shame. Virtually all modern programming languages trace their roots back to C and C++. The whole of Linux/UNIX traces its roots back to C. Our world is built on C/C++!</p>

<p>This is something I have neglected over recent years, so I’m going to change that. A bit of Google-fu just now has bought me some interesting resources:</p>

<pre><code>&lt;a href="http://www.cplusplus.com/doc/tutorial/" target="_blank" &gt;http://www.cplusplus.com/doc/tutorial/&lt;/a&gt;
&lt;a href="http://www.howtoforge.com/howtos/programming/c-cplusplus" target="_blank" &gt;http://www.howtoforge.com/howtos/programming/c-cplusplus&lt;/a&gt;
&lt;a href="http://www.gtk.org/tutorial1.2/" target="_blank" &gt;http://www.gtk.org/tutorial1.2/&lt;/a&gt;
&lt;a href="http://zetcode.com/tutorials/qt4tutorial/" target="_blank" &gt;http://zetcode.com/tutorials/qt4tutorial/&lt;/a&gt;
</code></pre>

<p>I have not looked at any of these in detail yet, but I will be over the next few days. At the end I hope to have dragged this hard-earned knowledge kicking and screaming from the back of my mind.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Add SAN functions to Highly Available NFS/NAS]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/02/20/add-san-functions-to-highly-available-nfs-slash-nas/"/>
    <updated>2012-02-20T21:07:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/02/20/add-san-functions-to-highly-available-nfs-slash-nas</id>
    <content type="html"><![CDATA[<p>This based on my last post where I documented building a Highly Available NFS/NAS server.</p>

<p>There is not a huge amount that needs to be done in order to add iSCSI functionality as well.</p>

<p>Add a file called <em>/etc/drbd/iscsi.res</em> containing:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource iscsi {
</span><span class='line'>    on nfs1 {
</span><span class='line'>        device /dev/drbd1;
</span><span class='line'>        disk   /dev/vdc;
</span><span class='line'>        meta-disk internal;
</span><span class='line'>        address   10.0.0.1:7789;
</span><span class='line'>    }
</span><span class='line'>    on nfs2 {
</span><span class='line'>        device /dev/drbd1;
</span><span class='line'>        disk   /dev/vdc;
</span><span class='line'>        meta-disk internal;
</span><span class='line'>        address   10.0.0.2:7789;
</span><span class='line'>    }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>This differs from the previous resource in 2 ways. Obviously it using a different physical disk. Also the port number of the address is incremented; each resource has to have its own port to communicate on.</p>

<h2>Configure Heartbeat</h2>

<p>Add a new resource to <em>/etc/ha.d/haresources</em>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iscsi1.snellwilcox.local IPaddr::10.0.0.101/24/eth0 drbddisk::iscsi tgtd</span></code></pre></td></tr></table></div></figure>


<p>Same primary host, new IP address, new drbd resource and of course the service to be controlled (tgtd in this case).</p>

<p>I also made a couple of changes to <em>/etc/ha.d/ha.cf</em>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>keepalive 500ms
</span><span class='line'>deadtime 5
</span><span class='line'>warntime 10
</span><span class='line'>initdead 120</span></code></pre></td></tr></table></div></figure>


<p>This changes the regularity of the heartbeat packets from every 2 seconds to 2 every second. We also say that a node is dead after only 5 seconds rather than after 30.</p>

<h2>Configure an iSCSI Target</h2>

<p>Tgtd has a config file that you can use in <em>/etc/tgt/targets.conf</em>. It is an XML file, so add entry like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;target iqn.2011-07.world.server:target0&gt;
</span><span class='line'>        # provided devicce as a iSCSI target
</span><span class='line'>        backing-store /dev/vg_matthew/lv_iscsi1
</span><span class='line'>        # iSCSI Initiator's IP address you allow to connect
</span><span class='line'>        initiator-address 192.168.1.20
</span><span class='line'>        # authentication info ( set anyone you like for "username", "password" )
</span><span class='line'>&lt;/target&gt;</span></code></pre></td></tr></table></div></figure>


<p>The target name is by convention <em>iqn.year-month.reverse-domainname:hostname.targetname</em>. Each backing store will be a seperate LUN. A discussion of this is out of the scope of this article.</p>

<p>By default, this config file is disabled. Enable it by un-commenting the line <code>#TGTD_CONFIG=/etc/tgt/targets.conf</code> in <em>/etc/sysconfig/tgtd</em>. You can now enable the target with service tgtd reload.</p>

<p>Now when you run <code>tgtadm –mode target –op show</code> you should get something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Target 1: iqn.2012-03.com.example:iscsi.target1
</span><span class='line'>    System information:
</span><span class='line'>        Driver: iscsi
</span><span class='line'>        State: ready
</span><span class='line'>    I_T nexus information:
</span><span class='line'>    LUN information:
</span><span class='line'>        LUN: 0
</span><span class='line'>            Type: controller
</span><span class='line'>            SCSI ID: IET     00010000
</span><span class='line'>            SCSI SN: beaf10
</span><span class='line'>            Size: 0 MB, Block size: 1
</span><span class='line'>            Online: Yes
</span><span class='line'>            Removable media: No
</span><span class='line'>            Readonly: No
</span><span class='line'>            Backing store type: null
</span><span class='line'>            Backing store path: None
</span><span class='line'>            Backing store flags:
</span><span class='line'>        LUN: 1
</span><span class='line'>            Type: disk
</span><span class='line'>            SCSI ID: IET     00010001
</span><span class='line'>            SCSI SN: beaf11
</span><span class='line'>            Size: 8590 MB, Block size: 512
</span><span class='line'>            Online: Yes
</span><span class='line'>            Removable media: No
</span><span class='line'>            Readonly: No
</span><span class='line'>            Backing store type: rdwr
</span><span class='line'>            Backing store path: /dev/drbd/by-res/iscsi
</span><span class='line'>            Backing store flags:
</span><span class='line'>    Account information:
</span><span class='line'>    ACL information:
</span><span class='line'>        ALL</span></code></pre></td></tr></table></div></figure>


<h2>Connect An Initiator</h2>

<p>Install the iscsi utils:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install iscsi-initiator-utils
</span><span class='line'>chkconfig iscsi on
</span><span class='line'>chkconfig iscsid on</span></code></pre></td></tr></table></div></figure>


<p>Discover the targets on the host and login to the target.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>iscsiadm -m discovery -t sendtargets -p 10.0.0.101
</span><span class='line'>iscsiadm -m node --login</span></code></pre></td></tr></table></div></figure>


<p>If you run <code>cat /proc/partitions</code> you will see an new partition has appeared. You can do whatever you want with it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Home-made Redundant Thin-provisioned SAN]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/02/08/home-made-redundant-thin-provisioned-san/"/>
    <updated>2012-02-08T20:02:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/02/08/home-made-redundant-thin-provisioned-san</id>
    <content type="html"><![CDATA[<p>The inspiration for this came from a mixture of problems I was having with my HP P2000, ideas that have been floating around my head for a while, plus a post over at Bauer-power.net. Basically I got given a bunch of warranty returned Supermicro servers from our Customer Service guys  and got tasked with making it our secondary VMware store and DR snapshot storage. Incidentally, the Supermicro servers are used for our Channel-in-a-box product for those you in the broadcast world. They are not ideal, the 2U 12 disk models that Pablo uses are far more suitable.</p>

<p>Plenty of companies already build their arrays on commodity hardware like these, so I am not doing anything new:</p>

<ul>
<li> Dell Compellent (Supermicro, soon to be Dell)</li>
<li> CoRAID (Supermicro)</li>
<li> EMC  Clarion and VNX</li>
<li> HP P4000 (HP DL180)</li>
<li> 3Par</li>
<li> Pure Storage</li>
<li> Nutanix</li>
<li> Solid Fire</li>
</ul>


<p>My set up is basically the same as that used by Pablo in the second iteration of his array:</p>

<ul>
<li> Linux</li>
<li> GlusterFS</li>
<li> Tgtd</li>
<li> Heartbeat</li>
</ul>


<p>There are a couple of differences:</p>

<ul>
<li> Mine uses a new version of GlusterFS which is currently in beta. This has several new features, the one I am interested in is Granular Locking. As I am storing VM images, I do not want these being locked during a self-heal – a problem in 3.2 and before. There are also other things such as object-storage (Amazon S3 compatible) for use with Open Stack. I’d love that, but I am not using it in my environment :( .</li>
<li> I am building on top of CentOS. I started with Red Hat and will continue to use it for server environments in the forceeable future.</li>
<li> I do not have de-duplication as I am not using ZFS, I am running on top of Ext4 and will use XFS or BTRFS if I need to. I am only using 8x 1TB drives as that is what I got given for free.</li>
</ul>


<p>I have had to build a couple of custom RPMS which I have made available in my <a href="http://yum.chriscowley.me.uk/el/6/x86_64/repoview/" target="blank">Yum repository</a>.</p>

<p>I did investigate de-duplication using LessFS, but sadly that is a no go as it does not currently support Extended Attributes, which are required by GlusterFS.</p>

<h2>Installation</h2>

<p>Install a basic CentOS 6 system on each node – the base system will be fine.</p>

<p>The two servers are</p>

<ul>
<li>server1 192.168.1.1(eth0),10.0.0.1(eth1)</li>
<li>server2 192.168.1.2(eth0),10.0.0.2(eth1)</li>
</ul>


<p>They connect to the rest of your network using eth0 and eth1 is a dedicated link between the 2. I would put them via a seperate switches/vLANs rather than a direct link, that way you can scale out your pool easily.</p>

<p>In the hosts file add:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>10.0.0.1 server1.example.com
</span><span class='line'>10.0.0.2 server2.example.com</span></code></pre></td></tr></table></div></figure>


<p>Add my repository:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rpm --import http://yum.chriscowley.me.uk/RPM-GPG-KEY-ChrisCowley
</span><span class='line'>yum install http://yum.chriscowley.me.uk/el/6/x86_64/RPMS/chriscowley-release-1-1.noarch.rpm
</span><span class='line'>rpm --import https://fedoraproject.org/static/0608B895.txt
</span><span class='line'>yum install http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-5.noarch.rpm</span></code></pre></td></tr></table></div></figure>


<p>Now you can install the necessary packages, which is not many. :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install glusterfs-core glusterfs-fuse heartbeat scsi-target-utils</span></code></pre></td></tr></table></div></figure>


<p>Now you can add create a pool of servers:</p>

<h2>GlusterFS</h2>

<p>From server1:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>gluster peer probe server2</span></code></pre></td></tr></table></div></figure>


<p>You next step is to configure a Gluster Volume. Gluster’s documentation for this is excellent. For our simple 2-node cluster we just want a simple replicated volume. As you grow, you can simple add extra pairs of nodes to expand your storage pool.</p>

<p>On each node create a folder to store the data and a mount-point for the replicated data:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir /exp1
</span><span class='line'>mkdir /mnt/test-volume</span></code></pre></td></tr></table></div></figure>


<p>Now create your volume and activate it(on a single node):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp1
</span><span class='line'>gluster volume start test-volume</span></code></pre></td></tr></table></div></figure>


<p>Now you need to mount that volume on each of your nodes.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "`hostname`:/test-volume /mnt/test-volume glusterfs defaults,noauto,_netdev 0 0" >> /etc/fstab
</span><span class='line'>echo "mount /mnt/test-volume" >> /etc/rc.local
</span><span class='line'>mount /mnt/test-volume</span></code></pre></td></tr></table></div></figure>


<h2>Heartbeat</h2>

<p>Now you need to configure heartbeat to control a floating IP address and the associated TGTD service. You need to create a few files on each node.</p>

<p>/etc/ha.d/authkeys:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>auth 2
</span><span class='line'>2 crc</span></code></pre></td></tr></table></div></figure>


<p>/etc/ha.d/ha.cf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>logfacility     local0
</span><span class='line'>keepalive 500ms
</span><span class='line'>deadtime 5
</span><span class='line'>warntime 10
</span><span class='line'>initdead 120
</span><span class='line'>bcast eth1
</span><span class='line'>node server1
</span><span class='line'>node server2
</span><span class='line'>auto_failback no</span></code></pre></td></tr></table></div></figure>


<p>/etc/ha.d/haresources:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>server1 IPaddr::192.168.1.3/24/eth0 tgtd</span></code></pre></td></tr></table></div></figure>


<p>There are a couple of considerations. The Gluster filesystems need to be mounted before tgtd starts. Tgtd is in turn controled by Heartbeat (see the above haresources file). To this end make sure both heartbeat and tgtd are disabled and start heartbeat from /etc/rc.local.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "/etc/init.d/heartbeat start" >> /etc/rc.local</span></code></pre></td></tr></table></div></figure>


<p>With all this done on both nodes, you can now start heartbeat on each node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/etc/init.d/heartbeat start</span></code></pre></td></tr></table></div></figure>


<p>Checking ifconfig will show that one of your nodes now has an <em>eth0:0</em> address.You will also find that tgtd is also running on that same node.</p>

<h2>iSCSI Target</h2>

<p>First create yourself a file to use as the backend for your iSCSI target:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dd if=/dev/zero bs=1M count=40000 of=/mnt/test-volume/test.img</span></code></pre></td></tr></table></div></figure>


<p>or, if you prefer thin provisioned:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dd if=/dev/zero bs=1M seek=40000 count=0 of=/mnt/test-volume/test.img</span></code></pre></td></tr></table></div></figure>


<p>You now need to define this file as a target. This requires the editting of 2 files.</p>

<p>/etc/sysconfig/tgtd:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TGTD_CONFIG=/etc/tgt/targets.conf</span></code></pre></td></tr></table></div></figure>


<p>/etc/tgtd/targets.conf, make sure there is an entry such as:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;target iqn.2012-02.com.example.gluster:isci>
</span><span class='line'>    backing-store /mnt/test-volume/test.img
</span><span class='line'>    initiator-address 192.168.1.10
</span><span class='line'>&lt;/target></span></code></pre></td></tr></table></div></figure>


<p>This will make that image file you created available to the client with the address 192.168.1.10. This targets.conf file is extremely well commented, so have a read. Now just tell tgtd to reload its configuration from the live node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/etc/init.d/tgtd reload</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>Nothing here is particularly complicated, but it does give you a lot of storage for a very low price, using a very enterprise friendly OS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VMware CLI installation woes on Centos 6]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2012/02/06/vmware-cli-installation-woes-on-centos-6/"/>
    <updated>2012-02-06T13:09:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2012/02/06/vmware-cli-installation-woes-on-centos-6</id>
    <content type="html"><![CDATA[<p>Installing the VMware CLI should have been simple, but it was a bit of a fiddle.</p>

<p>Use yum  all the bits it needs:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install make autoconf automake openssl-devel gcc gcc-c++ make uuid-perl libuuid-devel uuid-devel  perl-Data-Dump perl-SOAP-Lite perl-XML-SAX perl-XML-NamespaceSupport perl-XML-LibXML perl-XML-LibXML-Common perl-CPAN</span></code></pre></td></tr></table></div></figure>


<p>You should now be able to run the installer, but I had another problem though. The installer script would not believe me that I had a direct internet connection and insisted that I gave some proxy server settings. As a simple workaround I just commented out that code in the installation script:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if ( direct_command("env | grep -i http_proxy") ) {
</span><span class='line'> $httpproxy = 1;
</span><span class='line'>} else {
</span><span class='line'> print wrap("http_proxy not set. please set environment variable 'http_proxy' e.g. export http_proxy=http://myproxy.mydomain.com:0000 . \n\n", 0);
</span><span class='line'>}
</span><span class='line'>if ( direct_command("env | grep -i ftp_proxy") ) {
</span><span class='line'> $ftpproxy = 1;
</span><span class='line'>} else {
</span><span class='line'> print wrap("ftp_proxy not set. please set environment variable 'ftp_proxy' e.g. export ftp_proxy=http://myproxy.mydomain.com:0000 . \n\n", 0);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if ( !( $ftpproxy && $httpproxy)) {
</span><span class='line'>    uninstall_file($gInstallerMainDB);
</span><span class='line'>    exit 1;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>After this I was able to run the installer with no problems. Of course, there is still the problem I have VMware about them putting their files under <em>/usr</em>. If it is not under control of my package manager, the default should be <em>/opt</em> or <em>/usr/local</em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Source Storage]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2011/11/10/open-source-storage/"/>
    <updated>2011-11-10T13:12:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2011/11/10/open-source-storage</id>
    <content type="html"><![CDATA[<p>I have searchstorage.co.uk send me potentially interesting white-papers regularly. If I am honest, most of them or thinly veiled press-releases. However occasionally one is interesting.</p>

<p>Today I received one entitled <a href="http://http://warm-sword-7449.herokuapp.com//downloads/ITinEU_Storage_autumn11_final.pdf">Break free of vendor lock-in with open source storage</a>. Being a FLOSS fan and a storage specialist, that obviously intrigued me.</p>

<p>The article of interest starts on page 8 and is pretty good. It mentions all the main players; unusually it is not condescending towards Open Source (i.e. it will get you by until you can afford to buy a proper/stupidly-over-priced solution).</p>

<p>It also mentions <a href="http://www.gluster.org" target="_blank">GlusterFS</a>, which is particularly interesting. I have just built a solution at work built around this and it excellent. I will be putting more info up soon as a complete how-to on building a full-featured, high availability SAN/NAS.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu upgrade problems]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2011/10/16/ubuntu-upgrade-problems/"/>
    <updated>2011-10-16T13:24:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2011/10/16/ubuntu-upgrade-problems</id>
    <content type="html"><![CDATA[<p>Usually the release upgrade is relatively trouble-free, but this time I had a minor problem. After the upgrade I had no X Windows. It turned out that the NVidia driver not loading.</p>

<p>I had to boot it up in rescue mode, which is selectable from the Grub menu. From there I could drop to a root console.</p>

<p>The first step is to remount / as read-write and then mount my boot partition (/dev/sda1).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mount -o rw,remount /
</span><span class='line'>mount /dev/sda1 /boot</span></code></pre></td></tr></table></div></figure>


<p>Now I just need to move the xorg.conf to one side and reinstall the nvidia driver</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mv /etc/X11/xorg.conf /etc/X11/xorg.conf.bak
</span><span class='line'>apt-get remove nvidia-current && apt-get install nvidia-current</span></code></pre></td></tr></table></div></figure>


<p>After a reboot it should come up all fine and dandy.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SMS from Icinga or Nagios]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2010/05/04/sms-from-icinga-or-nagios/"/>
    <updated>2010-05-04T13:26:00+01:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2010/05/04/sms-from-icinga-or-nagios</id>
    <content type="html"><![CDATA[<p>Finding out how to have Nagios (or in my case Icinga) send SMS alerts is easy. However, from my point of view it fell down in 2 ways.</p>

<ol>
<li>Most of these guides are Debian specific, I am using Centos.</li>
<li>The SMS alerts are all or nothing, I only want SMS alerts for specific services (such as the corporate website).</li>
</ol>


<h2>Hardware</h2>

<p>First things first you need something to send the SMS. I am using a brand new Vodaphone USB dongle taped to the side of the rack . I also had it working with a Nokia E51 using the same tools – obviously this would the require constant charging.</p>

<p>Ideally I would have prefered to use an internal card. PCI -> PC card bridges do exist, but I had no joy on my Icinga server, although it did work in a Dell Optiplex we had lying around, but it caused an HP XW4600 not to switch on at all.</p>

<h2>Software</h2>

<p>I am using <a href="http://smstools3.kekekasvi.com/" target="_blank">SMS Server Tools 3</a> which are available for Centos/RHEL in <a href="https://fedoraproject.org/wiki/EPEL" target="_blank">EPEL</a>. This gives you an smsd daemon that watches a folder for text messages in a particular format.</p>

<p>When you have enabled EPEL run</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install smstools
</span><span class='line'>chkconfig –levels 35 smsd on</span></code></pre></td></tr></table></div></figure>


<p>When I plugged in the USB dongle I got a pair of USB ttys at /dev/ttyUSB0 and /dev/ttyUSB1</p>

<p>Add the following to /etc/smsd.conf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>devices = GSM1
</span><span class='line'>logfile = /var/log/smsd.log
</span><span class='line'>loglevel = 7
</span><span class='line'>
</span><span class='line'>ARVE Error: no video ID
</span><span class='line'>device = /dev/ttyUSB0
</span><span class='line'>smsc = 447785016005 # I am using Vodaphone, your’s may vary.
</span><span class='line'>incoming = no</span></code></pre></td></tr></table></div></figure>


<p>Now you can start the daemon</p>

<pre><code>/etc/init.d/smsd start
</code></pre>

<p>Finally, for reasons explained later, you need an entry in icinga’s cron.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>* * * * * if [[ `ls /tmp/ | grep 'sms-icinga' | wc -l` -gt 0 ]];then /bin/mv /tmp/sms-icinga* /var/spool/sms/outgoing/;fi</span></code></pre></td></tr></table></div></figure>


<p>What does this do? It checks “/tmp/” for any files that contain the name “sms-icinga” every minute. If any exist it moves them to “/var/spool/sms/outgoing/”. That last folder is watched by smsd for those special text files mentioned above.
Icinga/Nagios configuration</p>

<p>First add the commands, for which I use the file /etc/icinga/objects/commands.conf</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define command {
</span><span class='line'>    command_name notify-host-by-sms
</span><span class='line'>    command_line /usr/bin/printf “%b” “To: $CONTACTPAGER$\n\n$NOTIFICATIONTYPE$\nHost Alert: $HOSTNAME$ is $HOSTSTATE$\n” &gt; /tmp/sms-icinga.$HOSTNAME$.$HOSTSTATE$.$CONTACTPAGER$
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>define command {
</span><span class='line'>    command_name notify-service-by-sms
</span><span class='line'>    command_line /usr/bin/printf “%b” “To: $CONTACTPAGER$\n\n$NOTIFICATIONTYPE$\nService Alert:     $SERVICEDESC$ on $HOSTNAME$ is $SERVICESTATE$” &gt; /tmp/sms-icinga.$SERVICEDESC$.$HOSTNAME$.$CONTACTPAGER$
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>These commands write a file in /tmp that includes the string sms-icinga that our cron script looks for. The rest of it is to endure we do not accidentally overwrite an alert that has not been sent yet. The reason we need to write it into tmp, and the mv it to the outgoing folder is a little weird. I found that if I wrote directly to the outgoing folder, then smsd seemed picked it up too early and failed to parse the file correctly – strange, but not to worry.</p>

<p>Now is where need to fiddle things a little bit if we only want to send messages for certain critical services. If you want SMS alerts for all your services you can just add a pager entry to all you contacts. We need to create an SMS user and a couple of templates to base our critical stuff on.</p>

<p>The templates:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define contact {
</span><span class='line'>    name sms-contact
</span><span class='line'>    use generic-contact
</span><span class='line'>    service_notification_commands notify-service-by-sms, notify-service-by-email
</span><span class='line'>    host_notification_commands notify-host-by-sms, notify-host-by-email
</span><span class='line'>    register 0
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>define service {
</span><span class='line'>    use generic-service
</span><span class='line'>    name critical-service
</span><span class='line'>    contact_groups admins-sms,linux-admin
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>define host {
</span><span class='line'>    name critical-host
</span><span class='line'>    use generic-host
</span><span class='line'>    contact_groups admins-sms,linux-admin
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>my user:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define contact {
</span><span class='line'>    contact_name ChrisCowley-SMS
</span><span class='line'>    use sms-contact
</span><span class='line'>    pager &lt;my-mobile-number&gt;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>a contact group:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define contactgroup {
</span><span class='line'>    contactgroup_name admins-sms
</span><span class='line'>    members ChrisCowley-SMS
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Finally we can create our essential service:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define service {
</span><span class='line'>    use critical-service
</span><span class='line'>    service_description Website-content
</span><span class='line'>    check_command check_http_content!-U http://www.snellgroup.com -m Snell
</span><span class='line'>    host_name www.snellgroup.com
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some great new SAN gear]]></title>
    <link href="http://http://warm-sword-7449.herokuapp.com//blog/2010/01/12/some-great-new-san-gear/"/>
    <updated>2010-01-12T13:35:00+00:00</updated>
    <id>http://http://warm-sword-7449.herokuapp.com//blog/2010/01/12/some-great-new-san-gear</id>
    <content type="html"><![CDATA[<p>Just before Christmas I was up at a storage seminar run by a company called <a href="http://www.dothill.com/" target="_blank">Dot Hill</a>. Until I was pointed to them when I spoke to our storage supplier about replacing an aging array I had never heard of them. However, it turns out that they make the hardware used by HP, NetApp and others – quite a pedigree then.</p>

<p>All their products are completely modular, based on the same chassis. If you have an iSCSI unit, then you can later change it into a FC one and you do not have to migrate anything as the array config is not stored on the controllers.</p>

<p>They have some very clever technologies as well. In most arrays, the cache on the controllers need to be kept in sync. This generally goes through the backplane. In the Dot Hill arrays, there is dedicated circuitry that goes directly between the controllers – much faster! I also like the fact that they no longer use batteries, but instead use supercapacitors which are much greener.</p>
]]></content>
  </entry>
  
</feed>
